In many applications of Banach-valued analysis, the most natural assumption to make on the target Banach space is the \emph{UMD property}.
This can be characterised in various ways, but the characterisation which gives it its name is the unconditionality of difference sequences of martingales valued in the Banach space.
In this chapter we will consider `basic' characterisations and implications of this property.
In the next chapter, which is probably the most important in terms of applications, we will discuss consequences for Fourier multiplier theorems and Littlewood--Paley theory.

\section{Definition and first examples}

Recall that the difference sequence of a stochastic process $\mb{f}_{\bullet}$ is the stochastic process $d\mb{f}_{\bullet}$ defined by $d\mb{f}_{n} := \mb{f}_{n} - \mb{f}_{n-1}$, with $\mb{f}_{-1} := \mb{0}$.

\begin{defn}
  For $p \in (1,\infty)$ a Banach space $X$ is said to have the \emph{$\UMD_{p}$ property} (Unconditionality of Martingale Differences in $L^p$) if there exists a constant $C < \infty$ such that for all probability spaces $(\Omega,\mc{A},\P)$, all $X$-valued $L^p$-bounded martingales $\mb{f}_{\bullet}$, and all sequences of signs $\xi_n = \pm 1$,
  \begin{equation}\label{eq:UMD-property}
    \sup_{N \in \N} \Big\| \sum_{n=0}^{N} \xi_{n} d\mb{f}_{n} \Big\|_{L^p(\Omega;X)} \leq C \sup_{N \in \N} \Big\| \sum_{n=0}^{N} d\mb{f}_{n}\Big\|_{L^p(\Omega;X)}.
  \end{equation}
  The best possible constant $C$ in this inequality is denoted $\beta_{p}(X)$.
  We say that $X$ has the \emph{UMD property} if it has the $\UMD_{p}$ property for all $p \in (1,\infty)$.
\end{defn}

\begin{rmk}
  We will see in Section \ref{sec:UMD-p-independence} that the $\UMD_{p}$ property for some $p \in (1,\infty)$ implies the $\UMD$ property, so (as with the $p$-martingale convergence properties) there is no need to isolate $\UMD_{p}$ as a separate property other than for pedagogical reasons.
\end{rmk}

In Banach space lingo, \eqref{eq:UMD-property} says that the sequence $d\mb{f}_\bullet$ in $L^p(\Omega;X)$ is \emph{unconditional}, or equivalently, that the convergence (or divergence) in $L^p(\Omega;X)$ of the series $\sum_{n \in \N} d\mb{f}_n$ is independent of the order of summation.
Put very coarsely, the UMD property says that martingale differences behave somewhat like orthogonal sequences in $L^p(\Omega;X)$.
In fact, when $X$ is a Hilbert space, the $\UMD_{2}$ property follows directly from orthogonality considerations.

\begin{prop}
  Every Hilbert space $H$ has the $\UMD_{2}$ property, with best constant $\beta_{2}(H) = 1$.
\end{prop}

\begin{proof}
  Let $\mb{f}_{\bullet}$ be an $H$-valued martingale on a probability space $(\Omega,\mc{A},\P)$.
  Then for all sign sequences $\xi_{\bullet}$ and all $N \in \N$, since the differences $d\mb{f}_{n}$ are independent and hence pairwise orthogonal, we have
  \begin{equation*}
    \Big\| \sum_{n=0}^N \xi_{n} d\mb{f}_{n} \Big\|_{L^2(\Omega;H)}^{2}
    = \sum_{n = 0}^{N} \xi_{n}^{2} \|d\mb{f}_{n}\|_{L^2(\Omega;H)}^{2}
    = \sum_{n = 0}^{N} \|d\mb{f}_{n}\|_{L^2(\Omega;H)}^{2}
    = \Big\| \sum_{n=0}^N d\mb{f}_{n} \Big\|_{L^2(\Omega;H)}^{2}.
  \end{equation*}
  Thus we have equality in \eqref{eq:UMD-property}, with constant $C = 1$.
\end{proof}

At this point, without some extra theory, there isn't much we can say about spaces with $\UMD_{p}$ for $p \neq 2$ other than the following results.

\begin{prop}
  Let $p \in (1,\infty)$, and let $X$ be a Banach space.
  Then $X$ has the $\UMD_{p}$ property if and only if the dual space $X^{*}$ has the $\UMD_{p'}$ property, and $\beta_{p}(X) = \beta_{p'}(X^{*})$.
\end{prop}

\begin{proof}
  By rewriting the definition, we see that $X$ has the $\UMD_{p}$ property if and only if for all finite filtrations $(\mc{A}_{n})_{n = 0}^{N}$ on a probability space $(\Omega,\mc{A},\P)$ and all functions $\mb{f} \in L^p(\Omega;X)$, we have
  \begin{equation*}
    \Big\| \sum_{n=0}^{N} \xi_{n} d\mb{f}_{n} \Big\|_{L^p(\Omega;X)} \leq C \|\mb{f}\|_{L^p(\Omega;X)}, 
  \end{equation*}
  for all sequences of signs $(\xi_{n})_{n=0}^{N}$, where $\mb{f}_{n} = \E^{\mc{A}_{n}} \mb{f}$.
  That is, writing $T_{\mc{A}_{\bullet},\xi_{\bullet}}$ to denote the bounded linear operator
  \begin{equation*}
    \mb{f} \mapsto \sum_{n=0}^{N} \xi_{n} (\E^{\mc{A}_{n}} - \E^{\mc{A}_{n-1}})\mb{f},
  \end{equation*}
  we have that $X$ has the $\UMD_{p}$ property if and only if the operators $T_{\mc{A}_{\bullet},\xi_{\bullet}}$ are bounded on $L^p(\Omega;X)$ \emph{uniformly} over all probability spaces $(\Omega,\mc{A},\P)$, all finite filtrations $\mc{A}_{\bullet}$, and all finite sign sequences $\xi_\bullet$.
  Put concisely in terms of the constant $\beta_{p}(X)$, we have
  \begin{equation*}
    \beta_{p}(X) = \sup_{\Omega, \mc{A}_{\bullet}, \xi_{\bullet}} \|T_{\mc{A}_{\bullet}, \xi_{\bullet}}\|_{\Lin(L^{p}(\Omega;X))}.
  \end{equation*}

  Now fix a finite filtration $\mc{A}_{\bullet}$ on a probability space $(\Omega,\mc{A},\P)$, and a finite sign sequence $\xi_{\bullet}$.
  Suppose $\mb{f} \in L^{p}(\Omega;X)$ and $\mb{g} \in L^{p'}(\Omega;X^{*})$.
  Since the (scalar) conditional expectation $\E^{\mc{A}_{n}}$ on $L^p(\Omega)$ is adjoint to the corresponding conditional expectation on $L^{p'}(\Omega)$ (Proposition \ref{prop:CE-adjoint}), and since
  \begin{equation*}
    \langle \mb{f}, \E^{\mc{A}_{n}} \mb{g} \rangle = \langle \E^{\mc{A}_{n}} \mb{f}, \mb{g} \rangle
  \end{equation*}
  by Exercise \ref{ex:tensor-adjoint}, we get
  \begin{equation*}
    \langle \mb{f}, T_{\mc{A}_{\bullet}, \xi_{\bullet}} \mb{g} \rangle = \langle T_{\mc{A}_{\bullet}, \xi_{\bullet}} \mb{f}, \mb{g} \rangle 
  \end{equation*}
  Thus by the norming property of $L^{p'}(\Omega;X^{*})$ as a subset of $L^{p}(\Omega;X)^{*}$ (Proposition \ref{prop:bochner-preduality}), and of $L^{p}(\Omega;X)$ as a subset of $L^{p'}(\Omega;X^{*})^{*}$,\footnote{Technically we haven't proven this. The proof is a small modification of that of Proposition \ref{prop:bochner-preduality}, using that $X$ is a norming subspace of $X^{**} = (X^{*})^{*}$. See \cite[Proposition 1.3.1]{HNVW16} for the needed duality result in full generality.}  we get
  \begin{equation*}
    \begin{aligned}
      \|T_{\mc{A}_{\bullet}, \xi_{\bullet}}\|_{\Lin(L^{p}(\Omega;X))}
      &= \sup_{\mb{f}} \| T_{\mc{A}_{\bullet}, \xi_{\bullet}} \mb{f} \|_{L^{p}(\Omega;X)} \\
      &= \sup_{\mb{f}, \mb{g}} \langle T_{\mc{A}_{\bullet}, \xi_{\bullet}} \mb{f}, \mb{g} \rangle \\
      &= \sup_{\mb{f}, \mb{g}} \langle  \mb{f}, T_{\mc{A}_{\bullet}, \xi_{\bullet}} \mb{g} \rangle \\
      &= \sup_{\mb{g}} \| T_{\mc{A}_{\bullet}, \xi_{\bullet}} \mb{g} \|_{L^{p'}(\Omega;X^{*})}
      &= \|T_{\mc{A}_{\bullet}, \xi_{\bullet}}\|_{\Lin(L^{p'}(\Omega;X^{*}))},
  \end{aligned}
\end{equation*}
with suprema taken over all normalised $\mb{f} \in L^{p}(\Omega;X)$ and $\mb{g} \in L^{p'}(\Omega;X^{*})$.
Taking the supremum over all $\Omega$, $\mc{A}_{\bullet}$, and $\xi_{\bullet}$ then shows that
\begin{equation*}
  \beta_{p}(X) = \beta_{p'}(X^{*}), 
\end{equation*}
completing the proof.
\end{proof}

\begin{prop}
  Let $p \in (1,\infty)$, and suppose $X$ is a Banach space with the $\UMD_{p}$ property.
  Let $(S,\mc{A},\mu)$ be a measure space with $\mu(S) > 0$.
  Then the Bochner space $L^p(\mu;X)$ has $\UMD_{p}$, with $\beta_{p}(L^p(\mu;X)) = \beta_{p}(X)$.
\end{prop}

\begin{proof}
  To avoid confusion let $Y = L^p(\mu;X)$, and let $\mb{f}_{\bullet}$ be a $Y$-valued martingale on a probability space $(\Omega,\mc{A},\P)$.
  Then for all $N \in \N$, by wrapping the $\UMD_{p}$ property of $X$ in two applications of Fubini's theorem, we have
  \begin{equation*}
    \begin{aligned}
      \Big\| \sum_{n=0}^N \xi_{n} d\mb{f}_{n} \Big\|_{L^p(\Omega;Y)}^{p}
      &= \int_{\Omega} \int_{S} \Big\| \sum_{n=0}^N \xi_{n} d\mb{f}_{n}(\omega) \Big\|_{X}^{p} \, \dd\mu(s) \, \dd\P(\omega) \\
      &=  \int_{S} \Big( \int_{\Omega} \Big\| \sum_{n=0}^N \xi_{n} d\mb{f}_{n}(\omega) \Big\|_{X}^{p}  \, \dd\P(\omega) \Big) \, \dd\mu(s) \\
      &\leq \beta_{p}(X)^{p} \int_{S} \Big( \int_{\Omega} \Big\| \sum_{n=0}^N d\mb{f}_{n}(\omega) \Big\|_{X}^{p}  \, \dd\P(\omega) \Big) \, \dd\mu(s) \\
      &= \beta_{p}(X)^{p} \int_{\Omega}  \int_{S} \Big\| \sum_{n=0}^N d\mb{f}_{n}(\omega) \Big\|_{X}^{p}   \, \dd\mu(s) \, \dd\P(\omega) \\
      &= \beta_{p}(X)^{p} \Big\| \sum_{n=0}^N d\mb{f}_{n} \Big\|_{L^p(\Omega;Y)}^{p},
    \end{aligned}
  \end{equation*}
  which establishes $\beta_{p}(Y) \leq \beta_{p}(X)$.
  The reverse estimate is Exercise \ref{ex:UMD-Lp-reverse}.
\end{proof}

\section{$p$-independence of the UMD property}\label{sec:UMD-p-independence}

Our goal now is to prove that the $\UMD_{p}$ property is independent of $p$, so that from now on we need only refer to the UMD property (without mentioning an exponent $p$).

\begin{thm}\label{thm:UMD-p-independent}
  Let $X$ be a Banach space which has the $\UMD_{p}$ property for some $p \in (1,\infty)$.
  Then $X$ has $\UMD_{q}$ for all $q \in (1,\infty)$ (i.e. $X$ is UMD).
\end{thm}

We'll prove this as a result of \emph{Gundy's decomposition} for martingales, which is analogous to the Calder\'on--Zygmund decomposition of a function.

\begin{thm}[Gundy's decomposition]\label{thm:gundy}
  
\end{thm}

Now we prove the $p$-independence of the UMD property, assuming the Gundy decomposition.

\begin{proof}[Proof of Theorem \ref{thm:UMD-p-independent}, assuming Theorem \ref{thm:gundy}]
  
\end{proof}

\begin{cor}
  Hilbert spaces and $L^p$-spaces are UMD
\end{cor}

\begin{rmk}
  Remark on how the constant $\beta_{p}(X)$ varies.
\end{rmk}

\begin{rmk}
  Remark on exact values of $\beta_{p}(H)$ (Burkholder).
\end{rmk}

Finally, we return to the proof of Gundy's decomposition.

\begin{proof}[Proof of Theorem \ref{thm:gundy}]
  
\end{proof}

\section{Applications to martingale transforms and Haar decompositions}

-martingale transforms are bounded
-Haar decompositions are unconditional

\section{Stein's inequality: $R$-boundedness of conditional expectations}

\section{Sufficiency of dyadic martingales}

\section{UMD and reflexivity}

UMD implies reflexive, hence also RNP

\section{Examples and counterexamples}

Bunch of counterexamples from non-reflexivity
State Qiu's counterexample
give a few more if possible...

\section*{Exercises}

\begin{exercise}\label{ex:UMD-isomorphism}
  Let $X$ be a Banach space and $Y$ a closed subspace of $X$.
  Suppose that $Z$ is a Banach space and $\map{\phi}{Z}{Y}$ is an isomorphism.
  Show that 
  \begin{equation*}
    \beta_{p}(Z) \leq \|\phi\|_{\Lin(Z,Y)} \|\phi^{-1}\|_{\Lin(Y,Z)} \beta_{p}(X) \qquad \forall p \in (1,\infty).
  \end{equation*}
\end{exercise}

\begin{exercise}\label{ex:UMD-Lp-reverse}
  Let $X$ be a Banach space and $(S,\mc{A},\mu)$ be a measure space with $\mu(S) > 0$.
  For $p \in (1,\infty)$, show that $\beta_{p}(L^p(\mu;X)) \geq \beta_{p}(X)$.
\end{exercise}

\begin{exercise}
  (boundedness of martingale transforms on UMD spaces with $R$-bounded coefficients)
\end{exercise}

\begin{exercise}
  $\UMD_{p}$ implies randomised $\UMD_{p}$.
  Randomised $\UMD_{p}$ are all equivalent.
  $L^1$ is 'UMD-'.
\end{exercise}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main.tex"
%%% End:
