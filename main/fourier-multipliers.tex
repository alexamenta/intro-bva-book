Many important operators in (scalar-valued) Fourier analysis are \emph{Fourier multipliers}.\index{Fourier multiplier}
For each frequency $\xi \in \R$, such an operator maps the complex exponential function $x \mapsto e^{ix\xi}$ to the scalar multiple $m(\xi)e^{ix\xi}$ for some function $\map{m}{\R}{\C}$, called the \emph{symbol}.
\emph{Fourier multiplier theorems} generally give sufficient conditions for an operator $T_{m}$, defined as above, to be defined and bounded on $L^{p}(\R)$ for some or all $p \in (1,\infty)$.
These sufficient conditions usually involve smoothness requirements on the symbol $m$.
% The closely-related \emph{Littlewood--Paley theorem} gives an equivalent expression for the $L^p$ norm of a function in terms of square functions related to Fourier projections.

Naturally, many Fourier multiplier theorems have Banach-valued extensions, particularly when the Banach spaces involved have the UMD property.
Fourier multipliers on Banach-valued functions are intrinsically more complicated, as complex exponentials now have `direction' given by vectors $\mb{x} \in X$, and a Fourier multiplier on $X$-valued functions will now map elementary tensors $x \mapsto e^{i\xi x}\mb{x}$ to $e^{i\xi x}M(\xi)(\mb{x})$, where $M(\xi)$ is an operator from $X$ to another Banach space $Y$, and if $X = Y$ this operator need not be given by scalar multiplication (although these `scalar-valued' symbols are still important).

The most important Fourier multiplier (to harmonic analysts, at least) is the Hilbert transform, which also has a natural representation as a \emph{singular integral operator}.
In these notes we will not consider more general singular integral operators, but these also have a rich Banach-valued theory which is deeply connected with the UMD property.
The Fourier multiplier theorems we will prove ultimately boil down to boundedness of the Hilbert transform, and this is where we will begin the chapter.

\section{The Hilbert transform}\index{Hilbert transform}

Recall from the introduction that the Hilbert transform of a scalar-valued function $\map{f}{\R}{\C}$ is defined by
\begin{equation*}
  Hf(x) := \frac{1}{\pi} \mathrm{p. v.} \int_{\R} f(x-y) \, \frac{\dd y}{y} := \frac{1}{\pi} \lim_{\substack{\varepsilon \downarrow 0 \\ E \uparrow \infty}} \int_{\varepsilon < |y| < E} f(x-y) \, \frac{\dd y}{y}
\end{equation*}
(the truncation of the integral can be done in different ways; this is not too important).
As stated above, the Hilbert transform is used in the proof of various Fourier multiplier theorems, but it also arises fundamentally in complex analysis.\index{Hilbert transform!connection with holomorphic functions}
Given a real-valued function $\map{f}{\R}{\R}$, there is a unique holomorphic function $F$ on the upper half-space $\C_{+} = \{z \in \C : \Im(z) > 0\}$ such that for almost all $x \in \R = \partial \C_{+}$, the real part $\Re(F)$ satisfies
\begin{equation*}
  \lim_{y \to 0} \Re(F(x+iy)) = f(x) \qquad \ae \,  x \in \R.
\end{equation*}
This function turns out to satisfy
\begin{equation*}
  \lim_{y \to 0} \Im(F(x+iy)) = Hf(x)  \qquad \ae \,  x \in \R.
\end{equation*}
Thus the Hilbert transform computes what is called the \emph{conjugate function} of a real-valued $\map{f}{\R}{\R}$.
See \cite[\textsection 5.1.2]{grafakos} for more details.
There are plenty of other applications of this operator (and its generalisations, notably the Riesz transforms) outside of complex analysis, but we will not consider them in this course.

Classical methods in harmonic analysis imply that the Hilbert transform is bounded on $L^p(\R)$ for all $p \in (1,\infty)$, while explicit computation of $Hf$ when $f = \1_{[0,1]}$ shows that $H$ is not bounded on $L^1(\R)$ or $L^\infty(\R)$.
In this chapter (and the next) we will consider Banach-valued extensions of the Hilbert transform.
In particular, we will show that these extensions are bounded on $L^p(\R;X)$ for $p \in (1,\infty)$ if and only if the Banach space $X$ has the UMD property.

Consider a Banach space $X$ and fix $p \in (1,\infty)$.
Recall from Chapter \ref{sec:Bochner-spaces} that the tensor extension $H \otimes I$ is defined on the algebraic tensor product $L^p(\R) \otimes X$ by its action on elementary tensors,
\begin{equation*}
  (H \otimes I)(f \otimes \mb{x}) := (Hf) \otimes \mb{x} \qquad \forall f \in L^p(\R), \mb{x} \in X.
\end{equation*}
The algebraic tensor product $L^p(\R) \otimes X$ is the linear span of such elementary tensors, so $H \otimes I$ is extended by linearity to all of $L^p(\R) \otimes X$.
Recall also that $H \in \Lin(L^p(\R))$ admits a bounded $X$-valued extension if and only if
\begin{equation*}
  \|(H \otimes I)\mb{f}\|_{L^p(\R;X)} \lesssim \|\mb{f}\|_{L^p(\R;X)} \qquad \forall \mb{f} \in L^p(\R) \otimes X.
\end{equation*}
In this case, we can define a bounded linear operator $\widetilde{H}_{X}$ on $L^p(\R;X)$ by density, with
\begin{equation*}
  \widetilde{H}_{X} \mb{f} := \lim_{n \to \infty} (H \otimes I)\mb{f}_{n}
\end{equation*}
whenever $\mb{f}_{\bullet}$ is a sequence in $L^p(\R) \otimes X$ such that $\mb{f}_{n} \to \mb{f}$ in $L^p(\R;X)$.
The operator $\widetilde{H}_{X}$ can be rightfully called `the Hilbert transform on $L^p(\R;X)$'.

The goal of the next few sections is to prove the following theorem.

\begin{thm}[Burkholder]\label{thm:Burkholder}\index{theorem!Burkholder}
  Suppose that $X$ is a UMD Banach space.
  Then for all $p \in (1,\infty)$, the Hilbert transform $H \in \Lin(L^p(\R))$ admits a bounded $X$-valued extension.
\end{thm}

To prove this, it suffices to prove that for all $0 < \varepsilon < E < \infty$, the \emph{truncated $X$-valued Hilbert transform}\index{Hilbert transform!truncations}
\begin{equation*}
  H_{\varepsilon,E}^{X} \mb{f}(x) :=  \frac{1}{\pi} \int_{\varepsilon < |y| < E} \mb{f}(x-y) \, \frac{\dd y}{y} = \frac{1}{\pi} \int_{\varepsilon < |x-y| < E} \mb{f}(y) \, \frac{\dd y}{x-y}
\end{equation*}
is bounded on $L^p(\R;X)$ \emph{uniformly in $\varepsilon$ and $E$}.
Since the kernel $\1_{(\varepsilon,E)}(y)/y$ is integrable, Young's inequality implies that $H_{\varepsilon,E}$ is bounded on $L^p(\R;X)$, but it does not provide uniformity in the truncation parameters.
Once we have established uniform boundedness of these operators on $L^p(\R;X)$, Theorem \ref{thm:Burkholder} follows by noting that for all $\mb{f} \in L^p(\R) \otimes X$
\begin{equation*}
  \begin{aligned}
    \|(H \otimes I)\mb{f}\|_{L^p(\R;X)}
    = \lim_{\varepsilon \downarrow 0, E \uparrow \infty} \|(H_{\varepsilon,E} \otimes I)\mb{f}\|_{L^p(\R;X)}
    &= \lim_{\varepsilon \downarrow 0, E \uparrow \infty} \|H_{\varepsilon,E}^{X}\mb{f}\|_{L^p(\R;X)} \\
    &\lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}
  \end{aligned}
\end{equation*}
(the limit is justified by the definition of the scalar-valued Hilbert transform $Hf(x) = \lim H_{\varepsilon, E}f(x)$ and the fact that $\mb{f} \in L^p(\R) \otimes X$ has finite-dimensional range).

The Hilbert transform commutes with translations and dilations, and anticommutes with reflections.
That is, defining
\begin{equation}\label{eq:symmetries}
  \Tr_{s} f (x) := f(x - s), \qquad \Dil_{\lambda} f(x) := \lambda^{-1/2}f(x/\lambda), \qquad   \Refl f(x) := f(-x),
\end{equation}
we have the identities\index{Hilbert transform!symmetries}
\begin{equation*}
  H(\Tr_{s} f) = \Tr_{s} (Hf), \qquad H(\Dil_{\lambda} f) = \Dil_{\lambda} H(f), \quad H(\Refl(f)) = -\Refl(Hf).
\end{equation*}
In fact, these properties characterise the Hilbert transform among all bounded linear operators on $L^2(\R)$ (and in fact on $L^p(\R)$ for all $p$), up to a scalar multiple: any operator $T \in \Lin(L^2(\R))$ satisfying these properties must satisfy $T = cH$ for some $c \in \C$.\footnote{This result appears as \cite[Exercise 5.1.11]{grafakos}; it follows relatively simply from the Fourier multiplier representation of $H$, which we will discuss later.}
Whatever methods we use to establish bounded Banach-valued extensions of the Hilbert transform must respect these invariances.
This idea leads us to the analysis of generalised dyadic systems.

\section{Generalised dyadic systems and shift operators}

To establish uniform bounds on the truncated Hilbert transforms $H_{\varepsilon, E}^{X}$ when $X$ is UMD, we will need to relate them to martingale transforms.
The transforms we will need are related to the Haar multipliers we considered in Section \ref{sec:haar-decomp}.
However, we will need not only the dyadic filtration on the unit interval $[0,1)$, but more general \emph{dyadic systems}\index{dyadic system} on $\R$.

\begin{defn}
  For all $j \in \Z$ let
  \begin{equation*}
    \mc{D}_{j}^{0} = \{2^{-j}[k, k+1) : k \in \Z\}
  \end{equation*}
  denote the set of all dyadic intervals in $\R$ of length $2^{-j}$, and let
  \begin{equation*}
    \mc{D}^{0} := \bigcup_{j \in \Z} \mc{D}_{j}^{0}
  \end{equation*}
  denote the \emph{standard dyadic system}\index{dyadic system!standard}---i.e. the set of all dyadic intervals in $\R$.
  For every two-sided (i.e. $\Z$-indexed) sequence $\omega \in \{0,1\}^{\Z}$, define for all $j \in \Z$
  \begin{equation*}
    \mc{D}_{j}^{\omega} := \mc{D}_{j}^{0} + \sum_{i > j} 2^{-i} \omega_{i}:
  \end{equation*}
  this is the set of all dyadic intervals of length $2^{-j}$ as before, but with left endpoints shifted by the number $\sum_{i > j} 2^{-i} \omega_{i} \in [0,2^{-j})$: this number has the binary representation
  \begin{equation*}
    2^{-j}(0.\omega_{j+1}\omega_{j+2}\ldots)_{2} .
  \end{equation*}
  Finally, define the \emph{$\omega$-shifted dyadic system}\index{dyadic system!shifted}
  \begin{equation*}
   \mc{D}^{\omega} := \bigcup_{j \in \Z} \mc{D}_{j}^{\omega}.
  \end{equation*}
\end{defn}

We call $\mc{D}^{\omega}$ a `dyadic system' because it satisfies the following property.\footnote{This is technically the \emph{definition} of a dyadic system of intervals in $\R$. \cite[Lemma 5.1.7]{HNVW16} then says that every such dyadic system is given by $\mc{D}^\omega$ for some $\omega$. More general notions of dyadic systems (not necessarily of intervals, not necessarily in $\R$) exist. A good reference on this topic is \cite{LN18}.}

\begin{prop}\label{prop:dyadicsystems}
  Suppose $\omega \in \{0,1\}^{\Z}$ and $j \in \Z$.
  Then every interval $I \in \mc{D}_{j}^{\omega}$ has length $2^{-j}$, and there exist intervals $I_{-}, I_{+} \in \mc{D}^{\omega}_{j+1}$ such that $I = I_{-} \cup I_{+}$.
\end{prop}

\begin{proof}
  By construction every interval $I \in \mc{D}_{j}^{\omega}$ has length $2^{-j}$.
  We have
  \begin{equation*}
    I = 2^{-j}[k,k+1) + \sum_{i > j} 2^{-i} \omega_{i}
  \end{equation*}
  for some $k \in \Z$.
  Let $k' := k - \omega_{j}$, and consider the intervals
  \begin{equation*}
    \begin{aligned}
      I_{-} &= 2^{-{j+1}}[2k', 2k'+1) + \sum_{i > j-1} 2^{-i} \omega_{i}, \\
      I_{+} &= 2^{-{j+1}}[2k'+1, 2k'+2) + \sum_{i > j-1} 2^{-i} \omega_{i}. 
    \end{aligned}
  \end{equation*}
  Both of these intervals are in $\mc{D}^{\omega}_{j-1}$, both have length $2^{-(j-1)}$, and they are adjacent.
  Thus their union is an interval of length $2^{-j}$.
  The left endpoint of $I_{-}$ is
  \begin{equation*}
    \begin{aligned}
    2^{-j+1}(2k') + \sum_{i > j-1} 2^{-i} \omega_{i}
    &= 2^{-j}(k - \omega_{j}) + 2^{-j} \omega_{j} + \sum_{i > j} 2^{-i} \omega_{i} \\
    &= 2^{-j}k + \sum_{i > j} 2^{-i} \omega_{i},
  \end{aligned}
  \end{equation*}
  which equals the left endpoint of $I$.
  Similarly, the right endpoint of $I_{+}$ is equal to the right endpoint of $I$.
  Thus $I = I_{-} \cup I_{+}$.
\end{proof}

\begin{rmk}\label{rmk:dyadic-dichotomy}
The intervals in a shifted dyadic system $\mc{D}^{\omega}$ also satisfy the \emph{dyadic dichotomy}:\index{dyadic dichotomy} if $I$ and $J$ are intervals in $\mc{D}^{\omega}$, then they are either comparable ($I \subseteq J$ or $J \subseteq I$) or disjoint ($I \cap J = \varnothing$).
Prove this yourself in Exercise \ref{ex:dyadic-dichotomy}.
\end{rmk}

Dyadic systems are not translation invariant: given an interval $I \in \mc{D}^{\omega}$ and a parameter $x \in \R$, it is generally not true that $I + x \in \mc{D}^{\omega}$.
However, the \emph{set of dyadic systems} is itself translation invariant.

\begin{prop}
  Let $\omega \in \{0,1\}^{\Z}$ and $x \in \R$.
  Then $\mc{D}^{\omega} + x = \mc{D}^{\omega'}$ for some $\omega' \in \{0,1\}^{\Z}$.
\end{prop}

\begin{proof}
  Suppose $I \in \mc{D}^{\omega}$, so that
  \begin{equation*}
    I = 2^{-j}[k, k+1) + \sum_{i > j} 2^{-i} \omega_{i}
  \end{equation*}
  for some $k \in \Z$.
  The parameter $x$ has a binary expansion
  \begin{equation*}
    x = \sum_{i \in \Z} 2^{-i} \eta_{i}
    = 2^{-j} \sum_{i \in \Z} 2^{j-i}\eta_{i}
    = 2^{-j} \big( \sum_{i \leq j} 2^{j-i}\eta_{i} + \sum_{i > j} 2^{j-i}\eta_{i} \Big) 
  \end{equation*}
  for some finitely supported $\eta \in \{0,1\}^{\Z}$.
  Letting $k_{j} = k + \sum_{i \leq j} 2^{j-i} \eta_{i} \in \Z$, we thus have
  \begin{equation*}
    \begin{aligned}
      I + x &= 2^{-j}[k_{j}, k_{j} + 1) + \sum_{i > j} 2^{-i} (\omega_{i} + \eta_{i}) \\
      &= 2^{-j}[k_{j}, k_{j} + 1) + \sum_{i > j} 2^{-i} \omega_{j}'
    \end{aligned}
  \end{equation*}
  where $\omega'$ is the (formal) binary expansion of the sum of the numbers with (formal) binary expansions $\omega$ and $\eta$.
  Thus $\mc{D}^{\omega} + x \subseteq \mc{D}^{\omega'}$, and a symmetric argument shows that $\mc{D}^{\omega'} \subseteq \mc{D}^{\omega} + x$.
  Therefore we have $\mc{D}^{\omega} + x = \mc{D}^{\omega'}$.
\end{proof}

As stated above, our methods will also need to be dilation invariant.
To this end we allow for an additional modification to our dyadic systems.

\begin{defn}\index{dyadic system!dilated}
  For $\omega \in \{0,1\}^{\Z}$ and $t > 0$, define the \emph{dilated dyadic system}
  \begin{equation*}
    t\mc{D}^{\omega} := \{tI : I \in \mc{D}^{\omega}\}.
  \end{equation*}
\end{defn}

If $t = 2^{j}$ for some $j \in \Z$, then $t\mc{D}^{\omega} = \mc{D}^{\omega'}$ where $\omega'$ is a shift of $\omega$.
Thus as long as we allow for arbitrary $\omega \in \{0,1\}^{\Z}$, we need only consider dilated dyadic systems $t\mc{D}^{\omega}$ for $t \in [1,2)$.
In the following sections we will refer to a translated shifted dyadic system $t\mc{D}^{\omega}$, for some $t \in [1,2)$ and $\omega \in \{0,1\}^{\Z}$, simply as a \emph{generalised dyadic system},\index{dyadic system!generalised} and we may suppress reference to $t$ and $\omega$ and denote it by $\mc{D}$.

\begin{rmk}
  Although we have not formally proven it, generalised dyadic systems satisfy the conclusion of Proposition \ref{prop:dyadicsystems} (with length $t2^{-j}$ in place of $2^{-j}$) and the dyadic dichotomy (Remark \ref{rmk:dyadic-dichotomy}).  
\end{rmk}


Why do we need generalised dyadic systems?
Consider the probability space $\Omega := [1,2) \times \{0,1\}^{\Z}$, where $[1,2)$ is equipped with a probability measure $\nu$ and each factor $\{0,1\}$ has the uniform probability measure.
Since our set of generalised dyadic systems is parametrised by $\Omega$, we can consider `random dyadic systems', and associated `random martingale transforms'.
We are also able to take \emph{expectations} of such random martingale transforms.
By the construction of our shifted and dilated dyadic systems, these expectations will satisfy the same translation, dilation, and reflection invariances as the Hilbert transform.\footnote{For reflection invariance of shifted dyadic systems see Exercise \ref{ex:dyadic-refln-invariance}.}
With a bit of work, we will be able to recover truncated Hilbert transforms as expectations of random martingale transforms, and thus deduce uniform bounds for truncated Hilbert transforms from the UMD property.

From generalised dyadic systems we can construct generalised Haar expansions.
Recall from Proposition \ref{prop:haar-sqfn} that for all $\mb{f} \in L^p([0,1);X)$ with $p \in (1,\infty)$ and $X$ a UMD space, we have 
  \begin{equation*}
    \begin{aligned}
    \|\mb{f}\|_{L^p([0,1);X)}
    &\simeq_{p,X} \E \Big\| \varepsilon_{\varnothing} \langle \mb{f} \rangle_{[0,1)} +  \sum_{I \in \mc{D}} \varepsilon_{I} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p([0,1);X)} \\
    &= \E \Big\| \tilde{\varepsilon}_{0} \langle \mb{f} \rangle_{[0,1)} + \sum_{I \in \mc{D}} \tilde{\varepsilon}_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p([0,1);X)}
  \end{aligned}
\end{equation*}
where $\mc{D}$ is the standard dyadic system on $[0,1)$.
% Since the union of the finite Rademacher spaces $\varepsilon_{n}(X)$ is dense in $\varepsilon(X)$ (Exercise \ref{ex:on-rad-spaces}), it follows that the set of functions $\mb{f} \in L^p([0,1);X))$ with finitely many nonzero Haar coefficients is dense in $L^p([0,1);X)$.
This can be extended to general dyadic systems on $\R$: for any bounded interval $I \subset \R$ (not necessarily dyadic) we define the Haar function
\begin{equation*}
  h_{I} := |I|^{-1/2}(\1_{I_{-}} - \1_{I_{+}})
\end{equation*}
where $I_{-}$ and $I_{+}$ are the left and right halves of the interval $I$.

\begin{thm}\label{thm:general-haar-decompositions}\index{Haar decomposition!and generalised dyadic systems}
  Let $X$ be a UMD Banach space, $p \in (1,\infty)$, and let $\mc{D}$ be a generalised dyadic system.
  Then for all $\mb{f} \in L^p(\R;X)$,
  \begin{equation}\label{eq:gen-haar-sqfn}
      \|\mb{f}\|_{L^p(\R;X)}
      \simeq_{p,X} \E \Big\| \sum_{I \in \mc{D}} \varepsilon_{I} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} 
      = \E \Big\| \sum_{I \in \mc{D}} \tilde{\varepsilon}_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}.
    \end{equation}
    % Furthermore, the set of functions $\mb{f} \in L^p(\R;X)$ such that the sequence $(\langle \mb{f}, h_{I} \rangle)_{I \in \mc{D}}$ is finitely supported is dense in $L^p(\R;X)$.
\end{thm}

\begin{proof}
  % As in the case of the unit interval, the density statement follows from \eqref{eq:gen-haar-sqfn} and abstract properties of Rademacher spaces.
  We will only prove the estimate
  \begin{equation*}
    \E \Big\| \sum_{I \in \mc{D}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} \lesssim_{p,X}     \|\mb{f}\|_{L^p(\R;X)},
  \end{equation*}
  as the remaining estimates can be deduced similarly (Exercise \ref{ex:mgale-reduction}).
  % rewrite if unconditionality is still needed
  By density, it suffices to prove the result for compactly supported $\mb{f}$.
  Under this assumption, there exists a scale $j_{0} \in \Z$ such that the support of $\mb{f}$ is covered by the union of two adjacent intervals $I_{j}^{0}, I_{j}^{1} \in \mc{D}_{j}$ for all $j \leq j_{0}$.\footnote{The union of these intervals need not be an element of $\mc{D}^{\omega}_{j-1}$: consider for example the standard dyadic system and the function $\1_{[-1/4,1/4)}$.
    The support of this function is covered by the standard dyadic intervals $[-1/2,0)$ and $[0,1/2)$, but $[-1/2,1/2)$ is not a standard dyadic interval.}
  Let $I_{j} := I_{j}^{0} \cup I_{j}^{1}$ be the union of these two intervals.
  We fix $j \leq j_{0}$ and separate the contributions of small and large intervals to the Rademacher average: 
  \begin{equation*}
    \begin{aligned}
      &\E \Big\| \sum_{I \in \mc{D}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} \\
      &\leq \E \Big\| \sum_{k \geq j} \sum_{\substack{I \in \mc{D}_{k} \\ I \subseteq I_{j}}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
      + \E \Big\| \sum_{k < j} \sum_{\substack{I \in \mc{D}_{k} \\ I \supset I_{j}}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)},
    \end{aligned}
  \end{equation*}
  exploiting the dyadic dichotomy to restrict to intervals comparable to $I_{j}$.
  
  The contribution from large intervals can be estimated crudely by
  \begin{equation*}
    \begin{aligned}
      \E \Big\| \sum_{k < j} \sum_{\substack{I \in \mc{D}_{k} \\ I \supset I_{j}}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
      &\leq \sum_{k < j} \sum_{\sigma = 0,1} \big\| h_{I^{\sigma}_{k}} \otimes \langle \mb{f}, h_{I^{\sigma}_{j}} \rangle \big\|_{L^p(\R;X)} \\
      &\leq \sum_{k < j} \sum_{\sigma = 0,1} \|h_{I^{\sigma}_{k}}\|_{p} \| \langle \mb{f}, h_{I^{\sigma}_{j}} \rangle \|_{X} \\
      &\leq  \sum_{k < j} \sum_{\sigma = 0,1} |I_{k}^\sigma|^{\frac{1}{p}-\frac{1}{2}} \|\mb{f}\|_{L^1(\R;X)} |I_{k}^{\sigma}|^{-\frac{1}{2}} \\
      &\leq 2|I_{j_{0}}|^{1/p'} \|\mb{f}\|_{L^p(\R;X)} \sum_{k < j} 2^{-k(\frac{1}{p} - 1)} \\
      &\lesssim 2 |I_{j_{0}}|^{1/p'} \|\mb{f}\|_{L^p(\R;X)} 2^{j(1 - \frac{1}{p})}
    \end{aligned}
  \end{equation*}
  using that $\mb{f}$ is supported in $I_{j_{0}}$ to estimate the $L^1$ norm.

  To control the contribution from small intervals, we reduce to the probabilistic setting.
  Let $\P_{j}$ be the renormalised Lebesgue measure $|I_{j}|^{-1} \dd x$ on $I_{j}$.
  Then $(I_{j},\P_{j})$ is a probability space (with the Borel $\sigma$-algebra).
  Define a filtration $(\mc{F}_{n}^{j})_{n \in \N}$ on $I_{j}$ by
  \begin{equation*}
    \mc{F}_{n}^{j} := \sigma\{I \in \mc{D}_{j+n} : I \subset I_{j}\}.
  \end{equation*} 
  Then by the same argument we used to prove Proposition \ref{prop:haar-sqfn}---really we are just looking at a rescaled, shifted version of that result---we identify the generalised Haar decomposition with a martingale representation associated to the filtration $\mc{F}^{j}_{\bullet}$, and then invoke Burkholder's inequalities, with consequence that
  \begin{equation*}
    \begin{aligned}
      \E \Big\| \sum_{k \geq j} \sum_{\substack{I \in \mc{D}_{k}^{\omega} \\ I \subseteq I_{j}}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
      &=  |I_{j}|^{1/p} \E \Big\| \sum_{k \geq j} \sum_{\substack{I \in \mc{D}_{k}^{\omega} \\ I \subseteq I_{j}}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(I_{j}, \P_{j};X)} \\
      &\lesssim_{p,X} |I_{j}|^{1/p} \|\mb{f}\|_{L^p(I_{j},\P_{j};X)} 
      \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}
    \end{aligned}
  \end{equation*}
  using that $\mb{f}$ is supported in $I_{j}$.
  
  Putting the two terms together, for all $j \leq j_{0}$ we have
  \begin{equation*}
    \E \Big\| \sum_{I \in \mc{D}} \varepsilon_{I} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
    \lesssim_{p,X}  \|\mb{f}\|_{L^p(\R;X)} \Big(|I_{j_{0}}|^{1/p'}  2^{j(1 - \frac{1}{p})} + 1\Big),
  \end{equation*}
  so taking $j \downarrow -\infty$ completes the proof.
\end{proof}

\begin{rmk}
  This argument could have been avoided by considering conditional expectations and martingales on general $\sigma$-finite measure spaces, indexed over $\Z$ rather than $\N$, as is done in \cite{HNVW16}.
  The result would then follow from the `extended' UMD property defined via such martingales (which is, of course, equivalent to our UMD property).
\end{rmk}

The operators we will use to represent truncated Hilbert transforms are related to generalised Haar expansions, but with the Haar coefficients mapped onto a more general system of functions parametrised by a generalised dyadic system.
Notice that for every interval $I \subset \R$, the Haar function $h_{I}$ is just a translation and ($L^2$-normalised) dilation of the Haar function of the unit interval:
\begin{equation*}
  h_{I} = \Dil_{|I|} \Tr_{\ell(I)} h,
\end{equation*}
where $\ell(I) := \inf(I)$ is the left endpoint of $I$ and $h = h_{[0,1)}$.
This motivates a more general definition: given a function $\map{k}{\R}{\K}$ and an interval $I \subset \R$, define
\begin{equation*}
  k_{I} := \Dil_{|I|} \Tr_{\ell(I)} k.
\end{equation*}

\begin{defn}
  We say a function $\map{k}{\R}{\K}$ is an \emph{admissible base function}\index{admissible base function} if it is a finite $\K$-linear combination of Haar functions $h_{J}$ associated with standard dyadic intervals $J \subset [0,1)$ of a fixed length $2^{-j}$; in addition we require that $\|k\|_{\infty} \leq 1$.
\end{defn}

\begin{defn}
  Let $\mc{D} = t\mc{D}^{\omega}$ be a generalised dyadic system, $X$ a Banach space, and $k$ an admissible base function.
  For $m,n \in \Z$ with $m \leq n$ we define the \emph{truncated dyadic shift operator}\index{dyadic shift operator} $S_{k,m,n} = S_{k,m,n}^{t,\omega}$ by
  \begin{equation*}
    S_{k,m,n} \mb{f} := \sum_{I \in \mc{D}_{m,n}} k_{I} \otimes \langle \mb{f}, h_{I} \rangle \qquad \forall \map{\mb{f}}{\R}{X},
  \end{equation*}
  where we write $\mc{D}_{m,n} = \bigcup_{j = m}^{n} \mc{D}_{j}$.
\end{defn}

Although the indexing set $\mc{D}_{m,n}$ is infinite, for all $x \in \R$ the sum defining $S_{k,m,n}\mb{f}(x)$ is actually finite, as for each $j \in \Z$ there is at most one interval $I \in \mc{D}_{j}$ for which $k_{I}(x) \neq 0$ (as $k_{I}$ is supported in $I$), and only $m \leq j \leq n$ contribute to the sum.

\begin{rmk}
  In \cite{HNVW16} non-truncated dyadic shift operators $S_{k}$ are considered.
  We work with truncated shifts in order to avoid convergence issues.
\end{rmk}

When the admissible base function $k$ is the Haar function $h$ itself, $S_{h, m,n}$ acts as a \emph{Haar projection} to scales between $m$ and $n$: it sends a function to its partial Haar expansion onto intervals in $\mc{D}_{j}$ with $m \leq j \leq n$.
In general, since $k$ is a finite linear combination of Haar functions localised to equal-length subintervals of $[0,1)$, $S_{k}$ takes the generalised Haar projection of $\mb{f}$ and `shifts' each entry onto multiple Haar functions at a fixed smaller scale.

\begin{thm}\label{eq:shift-boundedness}\index{dyadic shift operator!boundedness in UMD spaces}
  Let $X$ be a UMD space, $p \in (1,\infty)$, $\mc{D}$ a generalised dyadic system, and $k$ an admissible base function.
  Then for all $m \leq n$, $S_{k,m,n}$ is bounded on $L^{p}(\R;X)$ uniformly in $m$ and $n$,
  with
  \begin{equation*}
    \|S_{k,m,n} \mb{f}\|_{L^p(\R;X)} \lesssim_{p,X} \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} k_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}.
  \end{equation*}
\end{thm}

\begin{proof}
  For each interval $I \in \mc{D}$, admissibility of $k$ means that we can write
  \begin{equation*}
    k_{I} = \sum_{\theta \in \Theta} \alpha_{\theta} h_{I_{\theta}},
  \end{equation*}
  where $\Theta$ is a finite indexing set, $\alpha_{\theta} \in \K$, and $I_{\theta} \in \mc{D}$ are subintervals of $I$ of length $2^{-\ell}|I|$ for some fixed $\ell \in \N$.
  Thus for $\mb{f} \in L^p(\R;X)$ we can write
  \begin{equation*}
    \begin{aligned}
      S_{k,m,n}\mb{f} = \sum_{\theta \in \Theta}  \sum_{I \in \mc{D}_{m,n}} \alpha_{\theta} h_{I_{\theta}} \otimes \langle \mb{f}, h_{I} \rangle .
    \end{aligned}
  \end{equation*}
  For each interval $J \in \mc{D}$ we have $J = I_{\theta}$ for at most one value of $I$ and $\theta$, so by Theorem \ref{thm:general-haar-decompositions} we can estimate
  \begin{equation*}
    \begin{aligned}
      \|S_{k,m,n} \mb{f}\|_{L^p(\R;X)}
      &= \Big\| \sum_{\theta \in \Theta} \sum_{I \in \mc{D}_{m,n}} \alpha_{\theta} h_{I_{\theta}} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} \\
      &\lesssim_{p,X} \E \Big\| \sum_{\theta \in \Theta} \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I_{\theta}|} \alpha_{\theta} h_{I_{\theta}} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} \\
      &= \E \Big\| \sum_{\theta \in \Theta} \sum_{I \in \mc{D}_{m,n}} \varepsilon_{2^{-\ell}|I|} \alpha_{\theta} h_{I_{\theta}} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}.
    \end{aligned}
   \end{equation*}
   By independence of the choice of Rademacher sequence, we have
   \begin{equation*}
     \begin{aligned}
       &\E \Big\| \sum_{\theta \in \Theta} \sum_{I \in \mc{D}_{m,n}} \varepsilon_{2^{-\ell}|I|} \alpha_{\theta}  h_{I_{\theta}} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)} \\
       &= \E \Big\| \sum_{\theta \in \Theta} \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} \alpha_{\theta} h_{I_{\theta}} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
       = \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} k_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)},
     \end{aligned}
   \end{equation*}
   which proves our first norm estimate.

   For the second norm estimate, we first note that the assumption $\|k\|_{\infty} \leq 1$ and the fact that $k$ is supported on $[0,1)$ implies that $|k_{I}(x)| \leq |h_{I}(x)|$ for all $x \in \R$.
   Thus by Kahane--Khitchine and the contraction principle,
   \begin{equation*}
     \begin{aligned}
       \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} k_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
       &\simeq_{p} \Big( \int_{\R} \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} k_{I}(x) \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{X}^{p} \, \dd x \Big)^{1/p} \\
       &= \Big( \int_{\R} \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} \frac{k_{I}(x)}{h_{I}(x)} h_{I}(x) \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{X}^{p} \, \dd x \Big)^{1/p} \\
       &\lesssim \Big( \int_{\R} \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} h_{I}(x) \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{X}^{p} \, \dd x \Big)^{1/p} \\
       &\simeq_{p} \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} h_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
     \end{aligned}
   \end{equation*}
   with the interpretation $\frac{k_{I}(x)}{h_{I}(x)} h_{I}(x) = 0$ when $h_{I}(x) = 0$.
   Applying Theorem \ref{thm:general-haar-decompositions} once more yields
   \begin{equation*}
     \E \Big\| \sum_{I \in \mc{D}_{m,n}} \varepsilon_{|I|} k_{I} \otimes \langle \mb{f}, h_{I} \rangle \Big\|_{L^p(\R;X)}
     \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)},
   \end{equation*}
   completing the proof.
 \end{proof}
 
 \section{Average truncated shifts and truncated Hilbert transforms}

 Since individual generalised dyadic systems $t\mc{D}^{\omega}$ are not translation or dilation invariant, neither are the shift operators $S_{k,m,n}^{\omega,t}$.
 But the set of all generalised dyadic systems is translation and dilation invariant, so averaging over $\omega$ and $t$ results in operators that have these invariances (at least in the formal `untruncated' limit as $m \downarrow -\infty$ and $n \uparrow \infty$).
 
 \begin{defn}
   Fix a UMD space $X$ and $p \in (1,\infty)$.
   Let $k$ be an admissible base function and $\nu$ a probability measure on $[1,2)$.
   For $m,n \in \Z$ with $m \leq n$ we define the \emph{average truncated dyadic shift operator}\index{dyadic shift operator!averaged} $\langle S_{k,m,n} \rangle^{\nu} \in \Lin(L^p(\R;X))$ by the $L^p(\R;X)$-valued Bochner integral
   \begin{equation}\label{eq:avg-shift}
     \langle S_{k,m,n} \rangle^{\nu}\mb{f} := \int_{[1,2)} \int_{\{0,1\}^{\Z}} S_{k,m,n}^{\omega, t}\mb{f} \, \dd \P(\omega) \, \dd \nu(t).
   \end{equation}
 \end{defn}
 
\begin{lem}
  For all Banach spaces $X$ and all $p \in (1,\infty)$, the $L^p(\R;X)$-valued Bochner integral \eqref{eq:avg-shift} exists.
\end{lem}

\begin{proof}
It suffices to show that the function $(\omega,t) \mapsto S_{k}^{\omega, t}\mb{f}$ is strongly measurable and bounded.
Boundedness follows from the fact that each of the truncated dyadic shifts $S_{k,m,n}^{\omega,t}$ is bounded on $L^p(\R;X)$, uniformly in $(\omega,t)$, by Theorem \ref{eq:shift-boundedness}.
For strong measurability, note that every $I \in t\mc{D}^{\omega}$ can be expressed as
\begin{equation}\label{eq:interval-parametrisation}
  I = 2^{-j}t([s,s+1) + \omega^{(j)}), \qquad \omega^{(j)} := \sum_{i > j} 2^{j-i} \omega_{i} \in [0,1]
\end{equation}
for some $s \in \Z$, so that
\begin{equation*}
  S_{k,m,n}^{\omega, t}\mb{f} = \sum_{j = m}^{n} \sum_{s \in \Z} k_{2^{-j}t([s,s+1) + \omega^{(j)})} \otimes \langle \mb{f}, h_{2^{-j}t([s,s+1) + \omega^{(j)})} \rangle.
\end{equation*}
Thus it suffices to show that the functions
\begin{equation*}
  (\omega,t) \mapsto k_{2^{-j}t([s,s+1) + \omega^{(j)})} \otimes \langle \mb{f}, h_{2^{-j}t([s,s+1) + \omega^{(j)})} \rangle
\end{equation*}
are strongly measurable.
This follows from the fact that the functions
\begin{equation*}
  \begin{aligned}
    (\omega,t) &\mapsto \langle \mb{f}, h_{2^{-j}t([s,s+1) + \omega^{(j)})} \rangle = \int_{\R} \mb{f}(y) h_{2^{-j}t([s,s+1) + \omega^{(j)})}(y) \, \dd y \in X\\
    (\omega,t) &\mapsto k_{2^{-j}t([s,s+1) + \omega^{(j)})} = \Dil_{2^{-j}t} \Tr_{2^{-j}t(s + \omega^{(j)})} k \in L^p(\R)
\end{aligned}
\end{equation*}
are continuous in $(\omega^{(j)},t)$.
\end{proof}

Having shown that the average truncated dyadic shifts $\langle S_{k,m,n} \rangle^{\nu}$ are well-defined as bounded operators on $L^p(\R;X)$, we turn to representing them in terms of more familiar convolution operators.

\begin{prop}\label{prop:shift-average-repn}\index{dyadic shift operator!representation of averages as convolutions}
  Let $X$ be a UMD space, $p \in (1,\infty)$, and let $\nu$ be a probability measure on $[1,2)$.
  Given an admissible base function $k$, let
  \begin{equation}\label{eq:phik}
    \phi^{k}(x) := \int_{\R} k(x+u)h(u) \, \dd u \qquad \forall x \in \R
  \end{equation}
  and for all $t > 0$ let $\phi^{k}_{t}(x) := t^{-1}\phi^{k}(x/t)$ be the $L^1$-normalised dilation of $\phi^{k}$.
  Then for all $\mb{f} \in L^p(\R;X)$ and all $m \leq n$,
  \begin{equation*}
    \langle S_{k,m,n} \rangle^{\nu} \mb{f} = \int_{2^{-n}}^{2^{-m+1}} \phi_{t}^{k} \ast \mb{f} \, \dd\tilde{\nu}(t),
  \end{equation*}
  where $\tilde{\nu}$ is the extension of $\nu$ to a measure on $(0,\infty)$ given by $\tilde{\nu}(A) := \nu(2^{-j}A)$ for all $A \subset [2^{j},2^{j+1})$, $j \in \Z$.
\end{prop}

\begin{proof}
  First we will compute
  \begin{equation*}
    \int_{\{0,1\}^{\Z}} \sum_{I \in t\mc{D}_{j}^{\omega}} k_{I}(x) \langle \mb{f}, h_{I} \rangle \, \dd\P(\omega)
  \end{equation*}
  for $x \in \R$, $t \in [1,2)$, and $j \in \Z$.
  Use the parametrisation of $I \in t\mc{D}_{j}^{\omega}$ from \eqref{eq:interval-parametrisation} to write this as
  \begin{equation*}
    \int_{\{0,1\}^{\Z}} \sum_{s \in \Z} k_{2^{-j}t([s,s+1) + \omega^{(j)})}(x) \langle \mb{f}, h_{2^{-j}t([s,s+1) + \omega^{(j)})} \rangle \, \dd\P(\omega).
  \end{equation*}
  Since the number $\omega^{(j)} \in [0,1]$ is uniformly distributed in $[0,1]$ as $\omega$ varies over $\{0,1\}^{\Z}$, this can be rewritten as
  \begin{equation*}
    \begin{aligned}
    &\int_{0}^{1} \sum_{s \in \Z} k_{2^{-j}t([s,s+1) + u)}(x) \langle \mb{f}, h_{2^{-j}t([s,s+1) + u)} \rangle \, \dd u \\
    &= \int_{\R}  k_{2^{-j}t[v,v+1)}(x) \langle \mb{f}, h_{2^{-j}t[v,v+1)} \rangle \, \dd v \\
    &= \int_{\R} (2^{-j} t)^{-1/2} k(2^{j} t^{-1} x - v)\int_{\R} (2^{-j} t)^{-1/2} h(2^{j} t^{-1} y - v)\mb{f}(y) \, \dd y \, \dd v \\
    &= \int_{\R} \Big[ (2^{-j} t)^{-1} \int_{\R} k(2^j t^{-1} x - v) h(2^j t^{-1} y - v) \, \dd v \Big] \mb{f}(y) \, \dd y .
  \end{aligned}
\end{equation*}
By the change of variable $u = (2^{-j}t)^{-1} y - v$, we see that for $y \in \R$ the square bracketed term is equal to
\begin{equation*}
  \begin{aligned}
    &(2^{-j} t)^{-1} \int_{\R} k(2^j t^{-1} x - v) h(2^j t^{-1} y - v) \, \dd v \\
    &= (2^{-j} t)^{-1} \int_{\R} k(2^j t^{-1} (x-y) + u) h(u) \, \dd u
    = \phi_{2^{-j} t}^{k}(x-y).
  \end{aligned}
\end{equation*}
Thus we have
\begin{equation*}
  \int_{\{0,1\}^{\Z}} \sum_{I \in t\mc{D}_{j}^{\omega}} k_{I}(x) \langle \mb{f}, h_{I} \rangle \, \dd\P(\omega)
  = \int_{\R} \phi_{2^{-j} t}^{k}(x-y) \mb{f}(y) \, \dd y
  = \phi_{2^{-j} t}^{k} \ast \mb{f}(x).
\end{equation*}
Summing over $m \leq j \leq n$ and integrating in $t \in [1,2)$, we have
\begin{equation*}
  \langle S_{k,m,n} \rangle^{\nu} \mb{f} = \int_{[1,2)} \sum_{j=m}^{n} \phi_{2^{-j} t}^{k} \ast \mb{f}   \, \dd\nu(t) = \int_{2^{-n}}^{2^{-m+1}} \phi^{k}_{t} \ast \mb{f} \, \dd\tilde{\nu}(t)
\end{equation*}
as claimed.
\end{proof}

Finally, by making two judicious choices of the measure $\nu$, we obtain bounds for convolution operators which seem to have little to do with dyadic shifts.
The right choices of $k$, and a little elbow grease, will yield uniform bounds for truncated Hilbert transforms, and will also be central in proving the Mikhlin and Littlewood--Paley theorems. 

\begin{cor}\label{cor:intop-bounds}
  Let $X$ be a UMD space, $p \in (1,\infty)$, and $k$ an admissible base function.
  With $\phi^{k}$ defined as in \eqref{eq:phik}, for all integers $m \leq n$ we have the bounds
  \begin{equation*}
    \begin{aligned}
      \Big\| \int_{2^{-n}}^{2^{-m+1}} \phi_{t}^{k} \ast \mb{f} \, \frac{\dd t}{t} \Big\|_{L^p(\R;X)} &\lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)} \\
      \E \Big\| \sum_{j = m}^{n} \varepsilon_{j} \phi_{2^{-j}}^{j} \ast \mb{f} \Big\|_{L^p(\R;X)} &\lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}.
    \end{aligned}
  \end{equation*}
  The implicit constants in these estimates are independent of $m$ and $n$.
\end{cor}

\begin{proof}
  The first estimate follows from Proposition \ref{prop:shift-average-repn} and Theorem \ref{eq:shift-boundedness}, by choosing $\nu = \frac{1}{\log(2)}\dd t/t$ (the factor $\frac{1}{\log(2)}$ makes $\nu$ a probability measure on $[1,2)$):
  \begin{equation*}
    \begin{aligned}
      \Big\| \int_{2^{-n}}^{2^{-m+1}} \phi_{t}^{k} \ast \mb{f} \, \frac{\dd t}{t} \Big\|_{L^p(\R;X)}
      &= \| \langle S_{k,m,n} \rangle^{\nu} \mb{f} \|_{L^p(\R;X)} \\
      &\leq \frac{1}{\log 2}\int_{[1,2)} \int_{\{0,1\}^{\Z}} \|S_{k,m,n}^{t,\omega} \mb{f} \|_{L^p(\R;X)} \, \dd\P(\omega) \, \frac{\dd t}{t} \\
      &\lesssim_{p,X} \frac{1}{\log 2} \int_{[1,2)} \int_{\{0,1\}^{\Z}} \| \mb{f} \|_{L^p(\R;X)} \, \dd\P(\omega) \, \frac{\dd t}{t} \\
      &= \|\mb{f}\|_{L^p(\R;X)}.
    \end{aligned}
  \end{equation*}
  The second estimate is proven in the same way, choosing $\nu = \delta_{1}$ (the Dirac measure at $t=1$) and using the randomised estimate from Theorem \ref{eq:shift-boundedness}.
\end{proof}

Now we pull an admissible base function $k$ out of thin air:\footnote{One motivation for this choice of $k$ is that the Hilbert transform swaps $\sin$ and $\cos$, which can be seen by the Fourier multiplier representation that we have not yet discussed. Thinking of a Haar function as a discrete sine wave, this choice of $k$ looks like a discrete cosine wave. So the associated shifts $S_{k}$ `map discrete sine to discrete cosine', and thus should somehow represent the Hilbert transform. Luckily, this actually works.} we take
\begin{equation*}
  k := 2^{-1/2}(h_{[0,1/2)} - h_{[1/2,1)}) = \1_{[0,1/4) \cup [3/4,1)} -\1_{[1/4, 3/4)}.
\end{equation*}
The function $\phi = \phi^{k}$, defined by
\begin{equation*}
  k(x) = \int_{\R} k(x+u)h(u) \, \dd u
\end{equation*}
as in the previous section, can be compute $\phi$ explicitly (Exercise \ref{ex:phi-computation}): it is the piecewise affine odd function supported on $[-1,1]$ which interpolates between the values
\begin{equation}\label{eq:phi-1}
  \begin{aligned}
    \phi(0) &= 0 \\
    \phi(1/4) &= -3/4 \\
    \phi(1/2) &= 0 \\
    \phi(3/4) &= 1/4 \\
    \phi(1) &= 0.
  \end{aligned}
\end{equation}
A graph of this function is given in \cite[Figure 5.1]{HNVW16}, but we only need to know that $\phi$ is odd and supported on $[-1,1]$, and that $\int_{0}^{1} \phi(y) \, \dd y = -1/8$ (and we only really need that $-1/8 \neq 0$).
We are ready to prove Theorem \ref{thm:Burkholder}, the boundedness of UMD-valued extensions of the Hilbert transform.

\begin{proof}[Proof of Theorem \ref{thm:Burkholder}]\index{theorem!Burkholder}
  As discussed above, it suffices to prove the bounds
  \begin{equation}\label{eq:HT-unifbds}
    \|H^{X}_{\varepsilon, E} \mb{f}\|_{L^p(\R;X)} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)} \qquad \forall \mb{f} \in L^p(\R;X)
  \end{equation}
  uniformly in $0 < \varepsilon < E < \infty$.
  Fix these parameters and consider the operator
  \begin{equation*}
    \int_{\varepsilon}^{E} \phi_{t} \ast \mb{f}(x) \, \frac{\dd t}{t}
  \end{equation*}
  with $\phi$ defined as above.
  Letting $\Phi(x) := \int_{0}^{x} \phi(s) \, \dd s$ be the primitive of $\phi$, we can write
  \begin{equation*}
    \begin{aligned}
    \int_{\varepsilon}^{E} \phi_{t} \ast \mb{f}(x) \, \frac{\dd t}{t}
    &= \int_{\R} \int_{\varepsilon}^{E} \phi(y/t) \, \frac{\dd t}{t^{2}} \, \mb{f}(x - y) \, \dd y \\
    &= \int_{\R} \frac{\Phi(y/\varepsilon) - \Phi(y/E) }{y} \, \mb{f}(x-y) \, \dd y
  \end{aligned}
\end{equation*}
by the fundamental theorem of calculus.
The properties of $\phi$ mentioned above imply that $\Phi$ is even, with $\Phi(y) = -1/8$ for all $y \in \R \sm [-1,1]$.
This lets us write
\begin{equation*}
  \frac{\Phi(y/\varepsilon)}{y}
  = \frac{1}{\varepsilon} \frac{\varepsilon}{y} \Big( \Phi\big(\frac{y}{\varepsilon}\big) \1_{[-1,1]}\big(\frac{y}{\varepsilon}) - \frac{1}{8}\1_{\R \sm [-1,1]}\big(\frac{y}{\varepsilon}\big) \Big) = \psi_{\varepsilon}(y) - \frac{1}{8y}\1_{(\varepsilon,\infty)}(|y|)
\end{equation*}
where $\psi(x) := x^{-1} \Phi(x) \1_{[-1,1]}(x)$.
and thus
\begin{equation*}
  \frac{\Phi(y/\varepsilon) - \Phi(y/E))}{y}
    = \psi_{\varepsilon}(y) - \psi_{E}(y) - \frac{1}{8y}\1_{[\varepsilon, E]}(|y|).
\end{equation*}
The last term is a nonzero multiple of the convolution kernel of $H_{\varepsilon, E}$, and rearranging everything leads to the representaton
\begin{equation*}
  \begin{aligned}
  -\frac{\pi}{8} H_{\varepsilon, E}\mb{f}
  &= \int_{2^{\lfloor \log_{2} \varepsilon \rfloor}}^{2^{\lfloor \log_{2} E \rfloor}} \phi_{t} \ast \mb{f} \, \frac{\dd t}{t} \\
  &+ \Big( \int_{2^{\lfloor \log_{2} E \rfloor}}^{E} - \int_{2^{\lfloor \log_{2} \varepsilon \rfloor}}^{\varepsilon} \Big) \phi_{t} \ast \mb{f} \, \frac{\dd t}{t} - \psi_{\varepsilon} \ast \mb{f} + \psi_{E} \ast \mb{f}.
\end{aligned}
\end{equation*}
The integral operator on the first line is uniformly bounded in $\varepsilon$ and $E$ on $L^p(\R;X)$ by Corollary \ref{cor:intop-bounds}, so it remains to deal with the second line, consisting of error terms.

First, note that
\begin{equation*}
  \begin{aligned}
    \|\phi_{t} \ast \mb{f}(x)\|_{X} &= t^{-1} \Big\| \int_{\R} \phi(y/t) \mb{f}(x-y) \, \dd y \Big\| \\
    &\lesssim t^{-1} \int_{\R} \1_{[-1,1]}(y/t) \mb{f}(x-y) \, \dd y \\
    &= \fint_{[x-t, x+t]} \|\mb{f}(y)\|_{X} \, \dd y \leq M(\|\mb{f}\|_{X})(x),
  \end{aligned}
\end{equation*}
since $\phi$ is bounded and supported on $[-1,1]$, where $M$ is the Hardy--Littlewood maximal operator\index{Hardy--Littlewood maximal operator}.
Since $\varepsilon$ and $E$ are within a factor $2$ of $2^{\lfloor \log_{2} \varepsilon \rfloor}$ and $2^{\lfloor \log_{2} E \rfloor}$ respectively, this implies that
\begin{equation*}
  \Big\| \Big( \int_{2^{\lfloor \log_{2} E \rfloor}}^{E} - \int_{2^{\lfloor \log_{2} \varepsilon \rfloor}}^{\varepsilon} \Big) \phi_{t} \ast \mb{f} \, \frac{\dd t}{t} \Big\|_{L^p(\R;X)}
  \lesssim \|M(\|\mb{f}\|)\|_{L^p(\R)} \lesssim \|\mb{f}\|_{L^p(\R;X)}
\end{equation*}
by the Hardy--Littlewood maximal theorem.
By the same reasoning, since
\begin{equation*}
  \psi(x) = \1_{[-1,1]}(x) x^{-1} \int_{0}^{x} \phi(s) \, \dd s
\end{equation*}
is also bounded and supported on $[-1,1]$, we get
\begin{equation*}
  \|\psi_{t} \ast \mb{f}(x)\|_{X} \lesssim M(\|\mb{f}\|_{X})(x),
\end{equation*}
and thus
\begin{equation*}
  \|\psi_{\varepsilon} \ast \mb{f} - \psi_{E} \ast \mb{f}\|_{L^p(\R;X)} \lesssim \|M(\|\mb{f}\|_{X})\|_{L^p(\R)} \lesssim \|\mb{f}\|_{L^p(\R;X)}.
\end{equation*}
This completes the proof.
\end{proof}

\section{Operator-valued Fourier multipliers and $R$-boundedness}

From now on we consider complex Banach spaces $X$, although the following theory has easily-established analogues for real Banach spaces.

Recall the definitions of the Fourier transform and its inverse from Definition \ref{defn:FT}: for $\mb{f} \in L^1(\R;X)$ we define the \emph{Fourier transform}\index{Fourier transform} $\hat{\mb{f}} \in C(\R;X)$ (the continuity is Exercise \ref{ex:FT-bounded-1-infty}) by 
  \begin{equation*}
    \hat{\mb{f}}(\xi) = \mc{F}(\mb{f})(\xi) := \int_{\R} e^{-2\pi i t \xi} \mb{f}(t)  \, \dd t \in X \qquad \forall \xi \in \R,
  \end{equation*}
  and the \emph{inverse Fourier transform} $\check{\mb{f}} \in C(\R;X)$
  \begin{equation*}
    \check{\mb{f}}(t) = \mc{F}^{-1}(\mb{f})(t) := \int_{\R} e^{2\pi i t \xi} \mb{f}(\xi) \, \dd \xi \in X \qquad \forall t \in \R
  \end{equation*}
  (note the simple identity $\check{\mb{f}}(\xi) = \hat{\mb{f}}(-\xi)$).
  For functions $\mb{f} \in L^1(\R;X)$ such that $\hat{\mb{f}} \in L^1(\R;X)$, the \emph{Fourier inversion formula}
  \begin{equation}\label{eq:fourier-inversion}
    \mb{f} = (\hat{\mb{f}})^\vee, \qquad \text{i.e.} \qquad \mb{f}(t) \aeeq \int_{\R} e^{2\pi i t \xi} \hat{\mb{f}}(\xi)  \, \dd\xi
  \end{equation}
  holds: this can be deduced by the corresponding result for the scalar-valued Fourier transform, but in this course it is not too important to us.
  We will, however, be interested in \emph{Fourier multipliers}: these are operators given by acting on the individual frequency components $\hat{\mb{f}}(\xi)$ in the representation \eqref{eq:fourier-inversion}.
  The rigorous definition follows.

\begin{defn}\index{Fourier multiplier}
  Let $X$ and $Y$ be complex Banach spaces, and consider a bounded operator-valued function $M \in L^\infty(\R;\Lin(X,Y))$.
  The Fourier multiplier $T_{M}$ is the operator $C^{\infty}_{c}(\R;X) \to C(\R;Y)$ defined by
  \begin{equation*}
    T_{M}\mb{f} := (M \cdot \hat{\mb{f}})^{\vee}, \qquad \text{i.e.} \qquad (T_{M}\mb{f})(t) = \int_{\R} e^{2\pi i t \cdot \xi} M(\xi)(\hat{\mb{f}}(\xi))  \, \dd\xi.
  \end{equation*}
\end{defn}

The operator-valued function $M$ is called the \emph{symbol}\index{symbol} of the operator $T_{M}$.
We should quickly show that this definition actually makes sense.

\begin{prop}
  If $\mb{f} \in C_{c}^\infty(\R;X)$ and $M \in L^\infty(\R;\Lin(X,Y))$, then $\hat{\mb{f}} \in L^1(\R;X)$ and $M \cdot \hat{\mb{f}} \in L^1(\R;Y)$ .
\end{prop}

\begin{proof}
  Once we know that $\hat{\mb{f}} \in L^1(\R;X)$, then $M \cdot \hat{\mb{f}} \in L^1(\R;Y)$ follows from strong measurability of the $Y$-valued function $M \cdot \hat{\mb{f}}$ (which can be proven either directly by approximation with simple functions, or by Pettis - we omit the argument) and the H\"older estimate $\|M \cdot \hat{\mb{f}}\|_{L^1(\R;Y)} \leq \|M\|_{L^\infty(\R;\Lin(X,Y))} \|\hat{\mb{f}}\|_{L^1(\R;X)}$.
  To show that $\hat{\mb{f}} \in L^1(\R;X)$, first split the integral into a part near the origin and a part `at infinity':
  \begin{equation*}
    \int_{\R} \|\hat{\mb{f}}(\xi)\|_{X} \, \dd\xi = \Big( \int_{[-1,1]} + \int_{\R \sm [-1,1]} \Big) \|\hat{\mb{f}}(\xi)\|_{X} \, \dd\xi.
  \end{equation*}
  The integral on $[-1,1]$ is bounded by $2\|\hat{\mb{f}}\|_{L^\infty(\R;X)}$, which is finite.
  The remaining integral can be bounded using a classic Fourier analytic technique coming from the identity $\widehat{\partial \mb{f}} = -i\xi \hat{\mb{f}}$:
  \begin{equation*}
    \begin{aligned}
    \int_{\R \sm [-1,1]} \|\hat{\mb{f}}(\xi)\|_{X} \, \dd\xi
    &= \int_{\R \sm [-1,1]} |\xi|^{-2} \|(-i\xi)^{2}\hat{\mb{f}}(\xi)\|_{X} \, \dd\xi \\
    &= \int_{\R \sm [-1,1]} |\xi|^{-2} \|\widehat{\partial^{2} \mb{f}}(\xi)\|_{X} \, \dd\xi \\
    &\leq \|\widehat{\partial^{2} \mb{f}}\|_{L^\infty(\R;X)} \int_{\R \sm [-1,1]} |\xi|^{-2} \, \dd\xi .
  \end{aligned}
\end{equation*}
The integral here is finite, and since $\mb{f}$ is smooth and compactly supported, 
\begin{equation*}
   \|\widehat{\partial^{2} \mb{f}}\|_{L^\infty(\R;X)} \leq \|\partial^{2} \mb{f}\|_{L^1(\R;X)} < \infty.
\end{equation*}
\end{proof}

Thus, at least for functions $\mb{f} \in C_{c}^\infty(\R;X)$ and symbols $M \in L^\infty(\R;\Lin(X,Y))$, we get a well-defined continuous function $T_{M}\mb{f} \colon \R \to Y$.
Now for each $p \in [1,\infty)$, the space $C_{c}^\infty(\R;X)$ is dense in $L^p(\R;X)$: this is because it contains the algebraic tensor product $C_{c}^\infty(\R) \otimes X$, which is dense in $L^p(\R;X)$ since $C_{c}^\infty(\R)$ is dense in $L^p(\R)$ (by a mollification argument).\footnote{Here we are relying on Exercise \ref{ex:general-density}.}
Thus we can ask ourselves the question: when does the operator $T_{M}$ extend by density to a bounded operator $L^p(\R;X) \to L^p(\R;Y)$?
That is, when do we have the estimate
\begin{equation*}
  \|T_{M} \mb{f}\|_{L^p(\R;Y)} \lesssim \|\mb{f}\|_{L^p(\R;X)} \qquad \forall \mb{f} \in C_{c}^\infty(\R;X)?
\end{equation*}

We have already studied one of the most important Fourier multipliers: the Hilbert transform.\index{Hilbert transform!as a Fourier multiplier}
A well-known result in harmonic analysis is the identification of the Hilbert transform $H$ as the Fourier multiplier $T_{m}$ with scalar-valued symbol\footnote{The value of $m(0)$ is irrelevant, as the operator $T_{m}$ only depends on the almost-everywhere equivalence class of $m$.)}
\begin{equation*}
  m(\xi) := -i\sgn(\xi) =
  \begin{cases}
    -i &\text{if $\xi > 0$} \\
    i &\text{if $\xi < 0$.}
  \end{cases}
\end{equation*}
We will not prove this here; see \cite[Proposition 5.2.2]{HNVW16}.
In Theorem \ref{thm:Burkholder} we established that $H = T_{m}$ extends to a bounded operator on $L^p(\R;X)$ whenever $X$ has the UMD property (and later on we will see that this characterises the UMD property).

Fourier multipliers occur all the time in applications, particularly in PDEs, and allowing for general operator-valued symbols is sometimes necessary.
Of course, for many applications it is sufficient to consider scalar-valued symbols (as in the case of the Hilbert transform).
Although the UMD condition turns out to be pretty much necessary for both operator-valued and scalar-valued symbols, the operator-valued context involves additional \emph{$R$-boundedness} assumptions on the symbol which are interesting in themselves.
We introduced $R$-boundedness in Exercise \ref{ex:R-bd-mgale-tf}, but we repeat the definition here. 

\begin{defn}
  Let $X$ and $Y$ be (real or complex) Banach spaces and suppose $\mc{T} \subset \Lin(X,Y)$ is a set of bounded linear operators from $X$ to $Y$.
We say that the set $\mc{T}$ is \emph{$R$-bounded}\index{R-bounds@$R$-bounds} if there exists a constant $C < \infty$ such that for all finite sequences $(T_{n})_{n=0}^{N}$ in $\mc{T}$ and $(\mb{x}_{n})_{n=0}^{N}$ in $X$,
\begin{equation*}
  \|T_{\bullet} \mb{x}_{\bullet}\|_{\varepsilon_{N}(Y)} \leq C \|\mb{x}_{\bullet}\|_{\varepsilon_{N}(X)},
\end{equation*}
or equivalently by Kahane--Khintchine (with a potentially different constant $\tilde{C}$)
\begin{equation}\label{eq:R1}
  \E \Big\| \sum_{n=0}^{N} \varepsilon_{n} T_{n} \mb{x}_{n} \Big\|_{Y} \leq \tilde{C} \E \Big\| \sum_{n=0}^{N} \varepsilon_{n}  \mb{x}_{n} \Big\|_{X}
\end{equation}
The best possible constant $C$ is denoted $R(\mc{T})$, and called the $R$-bound of the set of operators $\mc{T}$.\footnote{The best possible constant in \eqref{eq:R1} is sometimes denoted by $R_{1}(\mc{T})$, and Kahane--Khintchine yields $R_{1}(\mc{T}) \simeq R(\mc{T})$ with a constant independent of the set $\mc{T}$.}
\end{defn}

If $\mc{T} = \{T\}$ consists of a single operator, then
\begin{equation*}
  R(\{T\}) = \|T\|_{\Lin(X,Y)},
\end{equation*}
and if $\mc{T},\mc{T}' \subset \Lin(X,Y)$ with $\mc{T}' \subset \mc{T}$, then
\begin{equation*}
  R(\mc{T}') \leq R(\mc{T}).
\end{equation*}
Applying this to one-element subsets of $\mc{T}$ tell us that
\begin{equation*}
  R(\mc{T}) \geq \sup_{T \in \mc{T}} \|T\|_{\Lin(X,Y)},
\end{equation*}
so $R$-boundedness of a set of operators is a stronger condition than uniform boundedness.
Under quite restrictive type and cotype assumptions on $X$ and $Y$, $R$-boundedness is equivalent to uniform boundedness (see Exercise \ref{ex:R-bound-type}); in particular, if $X$ and $Y$ are isomorphic to Hilbert spaces, then this equivalence holds.
In general $R$-boundedness of a family of operators is strictly stronger than uniform boundedness, and estimating $R$-bounds requires some form of `compatibility' or `similarity' of the operators in the set.

\begin{example}\label{eg:R-bounded-multipliers}\index{R-bounds@$R$-bounds!of pointwise multiplication operators}
  Let $X$ be a Banach space, let $(S,\mc{A},\mu)$ be a $\sigma$-finite measure space, and fix $p \in [1,\infty)$.
  For each $g \in L^\infty(S)$ define the multiplication operator $M_{g} \in \Lin(L^p(S;X))$ by $M_{g}\mb{f} = g\mb{f}$.
  Then for all $C < \infty$, the set of operators
  \begin{equation*}
    \{M_{g}  : \|g\|_{L^\infty(S)} \leq C\} \subset \Lin(L^{p}(S;X))
  \end{equation*}
  is $R$-bounded.
  To see this, fix a finite sequence $(g_{n})_{n=0}^{N}$ in $L^\infty(S)$ with $\|g_{n}\|_{L^\infty(S)} \leq C$ for all $n$, and a finite sequence $(\mb{f}_{n})_{n=0}^{N}$ in $L^p(S;X)$.
  Then by Kahane--Khintchine and the contraction principle,
  \begin{equation*}
    \begin{aligned}
      \| M_{g_{\bullet}} \mb{f}_{\bullet} \|_{\varepsilon_{N}(L^p(S;X))}
      &\simeq_{p} \Big( \int_{\R} \E \Big\| \sum_{n=0}^{N} \varepsilon_{n} g_{n}(s) \mb{f}_{n}(s) \Big\|_{X}^{p} \, \dd\mu(s) \Big)^{1/p} \\
      &\lesssim C \Big( \int_{\R} \E \Big\| \sum_{n=0}^{N} \varepsilon_{n} \mb{f}_{n}(s) \Big\|_{X}^{p} \, \dd\mu(s) \Big)^{1/p} \\
      &\simeq_{p} C \| \mb{f}_{\bullet} \|_{\varepsilon_{N}(L^p(S;X))},
    \end{aligned}
  \end{equation*}
  proving the claimed $R$-boundedness.
\end{example}

\begin{example}\label{eg:R-bounded-unions}\index{R-bounds@$R$-bounds!of unions}
  Let $X$ and $Y$ be Banach spaces, and let $\mc{T}$ and $\mc{S}$ be $R$-bounded subsets of $\Lin(X,Y)$.
  Then $\mc{T} \cup \mc{S}$ is also $R$-bounded, with $R(\mc{T} \cup \mc{S}) \leq R(\mc{T}) + R(\mc{S})$.
  To see this, fix finite sequences $(T_{n})_{n=0}^{N}$ in $\mc{T} \cup \mc{S}$ and $(\mb{x}_{n})_{n=0}^{N}$ in $X$.
  Define
  \begin{equation*}
    A := \{n : T_{n} \in \mc{T}\}, \qquad B := \{0,1,\ldots,N\} \sm A.
  \end{equation*}
  so that $A \cup B = \{0,1,\ldots,N\}$.
  Then
  \begin{equation*}
    \begin{aligned}
      \|T_{\bullet} \mb{f}_{\bullet}\|_{\varepsilon_{N}(Y)}
      &\leq \|T_{\bullet} \mb{f}_{\bullet}\|_{\varepsilon_{A}(Y)} + \|T_{\bullet} \mb{f}_{\bullet}\|_{\varepsilon_{B}(Y)} \\
      &\leq R(\mc{T}) \| \mb{f}_{\bullet}\|_{\varepsilon_{A}(X)} + R(\mc{S}) \| \mb{f}_{\bullet}\|_{\varepsilon_{B}(X)} \\
      &\lesssim (R(\mc{T}) + R(\mc{S})) \|\mb{f}_{\bullet}\|_{\varepsilon_{N}(X)}
    \end{aligned}
  \end{equation*}
  writing $\varepsilon_{A}$ and $\varepsilon_{B}$ to denote Rademacher spaces indexed by the sets $A$ and $B$, and using the contraction principle in the last line.
  This example shows a useful general principle: if a set of operators can be decomposed into a finite union of $R$-bounded sets, then the original set is $R$-bounded.
\end{example}

The fundamental link between $R$-boundedness and Fourier multipliers comes from the following theorem, whose proof we omit.\footnote{It isn't too difficult, we just don't need it. For details see \cite[Theorem 5.3.15]{HNVW16}.}

\begin{thm}[Cl\'ement--Pr\"uss]\index{R-bounds@$R$-bounds!necessity for Fourier multipliers}
  Let $X$ and $Y$ be Banach spaces and $p \in (1,\infty)$.
  Let $M \in L^\infty(\R;\Lin(X,Y))$ be an operator-valued symbol such that the Fourier multiplier $T_{M}$ is bounded from $L^p(\R;X)$ to $L^p(\R;Y)$.
  Then the set\footnote{Recall that a point $\xi \in \R$ is a Lebesgue point of $M$ if $M(\xi) = \lim_{\varepsilon \downarrow 0} \fint_{\xi-\varepsilon}^{\xi+\varepsilon} M(\eta) \, \dd\eta $, and that almost every $\xi \in \R$ is a Lebesgue point of $M$.}
  \begin{equation*}
    \{M(\xi) : \text{$\xi \in \R$ is a Lebesgue point of $M$}\}
  \end{equation*}
  is $R$-bounded.
  In particular, if $M$ is continuous, then the range $M(\R) \subset \Lin(X,Y)$ is $R$-bounded.
\end{thm}

Thus $R$-boundedness is a necessary condition for the $L^p$-boundedness of an operator-valued Fourier multiplier.
In the next section we investigate sufficient conditions.
Before moving on to the Mikhlin theorem and its proof, we quickly discuss \emph{Fourier projections}.

\begin{defn}
  For every measurable subset $S \subset \R$ we define the \emph{Fourier projection}\index{Fourier projections} $\Delta_{S}$ to the Fourier multiplier $T_{\1_{S}}$ with scalar-valued symbol $\1_{S}$.
\end{defn}

\begin{prop}\label{prop:Fproj-Rbd}\index{R-bounds@$R$-bounds!of Fourier projections on UMD spaces}\index{Fourier projections!R-bounded for UMD spaces}
  Let $X$ be a complex UMD space and $p \in (1,\infty)$.
  Then for each interval $I \subset \R$ (including unbounded intervals), the Fourier projection $\Delta_{I}$ is bounded on $L^p(\R;X)$.
  Furthermore, the set of Fourier projections
  \begin{equation*}
    \{\Delta_{I} : \text{$I \subset \R$ an interval} \} \subset \Lin(L^p(\R;X))
  \end{equation*}
  is $R$-bounded.
\end{prop}

The proof relies on the intertwining relations between Fourier multipliers, translations, and modulations, where for $\eta \in \R$ we define the \emph{modulation}\index{modulation} of a function $\mb{f}$ (taking values in some Banach space) by
\begin{equation*}
  (\Mod_{\eta} \mb{f})(t) := e^{2\pi i \eta x} \mb{f}(t) \qquad \forall t \in \R.
\end{equation*}
By direct computation, for all Banach spaces $X,Y$ and symbols $M \in L^\infty(\R;\Lin(X,Y))$, for all $s \in \R$ and $\mb{f} \in C^{\infty}_{c}(\R;X)$,
\begin{equation*}
  T_{\Tr_{s} M} \mb{f} = \Mod_{s} T_{M} \Mod_{-s} \mb{f} \quad \text{and} \quad
  T_{\Mod_{s} M} \mb{f} = \Tr_{-s} T_{M} \mb{f}. 
\end{equation*}

\begin{proof}[Proof of Proposition \ref{prop:Fproj-Rbd}]
  Since the Hilbert transform is a Fourier multiplier with symbol
  \begin{equation*}
    m(\xi) = -i\sgn(\xi),
  \end{equation*}
   we have the identity
  \begin{equation*}
    iH = \Delta_{(0,\infty)} -\Delta_{(-\infty,0)}
  \end{equation*}
  and thus
  \begin{equation*}
    \frac{I + iH}{2} = \frac{\Delta_{\R} + \Delta_{(0,\infty)} -\Delta_{(-\infty,0)}}{2} = \Delta_{(0,\infty)}.
  \end{equation*}
  It follows that $\Delta_{(0,\infty)}$ is bounded on $L^p(\R;X)$.
  More generally, for $a,b \in \R$ we have
  \begin{equation*}
    \begin{aligned}
      \Delta_{(a,b)} &= \Delta_{(a,\infty)} - \Delta_{(b,\infty)} \\
      &= T_{\Tr_{a} \1_{(0,\infty)}} - T_{\1_{\Tr_{b} \1_{(0,\infty)}}} \\
      &= \Mod_{a} \Delta_{(0,\infty)} \Mod_{-a} - \Mod_{b} \Delta_{(0,\infty)} \Mod_{-b},
    \end{aligned}
  \end{equation*}
  so $\Delta_{(a,b)}$ is bounded on $L^p(\R;X)$.
  The same argument handles all half-infinite intervals $\Delta_{(a,\infty)}$ and $\Delta_{(-\infty,b)}$.

  For the $R$-boundedness, use the identities above to write
  \begin{equation*}
    \{\Delta_{I} : \text{$I \subset \R$ an interval}\}
    = \{\Mod_{a} \Delta_{(0,\infty)} \Mod_{-a} - \Mod_{b} \Delta_{(0,\infty)} \Mod_{-b} : a,b \in \R\} 
  \end{equation*}
  ignoring unbounded intervals for technical convenience (but of course they can be handled by the same argument).
  By the first bound in Exercise \ref{ex:R-bound-stuff} we get
  \begin{equation*}
    \begin{aligned}
      &R\big( \{\Delta_{I} \in \Lin(L^p(\R;X)) : \text{$I \subset \R$ an interval}\} \big) \\
      &\leq 2R\big( \{\Mod_{a} \Delta_{(0,\infty)} \Mod_{-a} \in \Lin(L^p(\R;X)) : a \in \R\}  \big),
  \end{aligned}
  \end{equation*}
  and by the second bound in Exercise \ref{ex:R-bound-stuff} we have
  \begin{equation*}
    \begin{aligned}
      &R\big( \{\Mod_{a} \Delta_{(0,\infty)} \Mod_{-a} \in \Lin(L^p(\R;X)) : a \in \R\}  \big) \\
      &\leq R\big( \{ \Mod_{a} \in \Lin(L^p(\R;X)) : a \in \R \} \big)^{2} \|\Delta_{(0,\infty)}\|_{\Lin(L^p(\R;X))}
    \end{aligned}
  \end{equation*}
  using that one-element sets of bounded operators are $R$-bounded.
  Since each operator $\Mod_{a}$ is just multiplication by a unimodular function (a complex exponential), Example \ref{eg:R-bounded-multipliers} gives us
  \begin{equation*}
    R\big( \{ \Mod_{a} \in \Lin(L^p(\R;X)) : a \in \R \} \big)
    \leq R\big( \{ M_{g} \in \Lin(L^p(\R;X))  : \|g\|_{L^\infty(\R)} \leq 1\} \big) \lesssim 1,
\end{equation*}
so the boundedness of $\Delta_{(0,\infty)}$ on $L^p(\R;X)$ that we proved earlier completes the proof.
\end{proof}


\section{The Mikhlin and Littlewood--Paley theorems}

We can now move to the Mikhlin multiplier theorem.
As shown by the Hilbert transform and Fourier projections $\Delta_{I}$, the symbol of an $L^p$-bounded Fourier multiplier can have discontinuities.
However, away from the endpoints of an interval $I \subset \R$, the symbol $\1_{I}$ of the Fourier projection $\Delta_{I}$ is quite regular (in this case, locally constant).
The class of \emph{Mikhlin symbols} have similar properties: they have discontinuities on a particular countable set of points (the dyadic numbers $\pm 2^{j}$ with $j \in \Z$, along with the origin), and on the dyadic intervals in between they are continuous and differentiable, with some scale-invariant control on the derivatives on these intervals.
We establish the boundedness of the associated Fourier multipliers on $L^p(\R;X)$, when $X$ is UMD and $p \in (1,\infty)$, essentially by representing them in terms of the Fourier projections $\Delta_{I}$, exploiting the $R$-boundedness of these operators, and using estimates proved earlier for average dyadic shift operators.

Let us formalise the definition of a Miklhin symbol.
We let $\mc{J}$ denote the set of \emph{Littlewood--Paley intervals}\index{Littlewood--Paley intervals}
\begin{equation*}
  \mc{J} := \{\pm(2^{j}, 2^{j+1}) : j \in \Z\}.
\end{equation*}
We lete $\mc{J}_{+}$ and $\mc{J}_{-}$ denote the set of Littlewood--Paley intervals contained in $\pm(0,\infty)$, so that $\mc{J} = \mc{J}_{+} \cup \mc{J}_{-}$.

\begin{defn}\label{defn:mikhlin-symbol}
  Given complex Banach spaces $X$ and $Y$, an operator-valued function $M \in L^\infty(\R; \Lin(X,Y))$ is called a \emph{Mikhlin symbol}\index{Mikhlin symbols} if it is continuous and differentiable on each Littlewood--Paley interval $I \in \mc{J}$, and if the \emph{Mikhlin norm}\index{Mikhlin norm}
  \begin{equation*}
    \|M\|_{\mf{M}(\R;X,Y)} := R \Big( \big\{ M(\xi), \xi M'(\xi) \in \Lin(X,Y) : \xi \in \bigcup_{I \in \mc{J}} I \big\} \Big)
  \end{equation*}
  is finite.
\end{defn}

Note that the union of Littlewood--Paley intervals in this definition can be written as
\begin{equation*}
  \bigcup_{I \in \mc{J}} I = \R \sm \big( \{0\} \cup \{\pm 2^{j} : j \in \Z\} \big).
\end{equation*}
Note also that if $X$ has cotype $2$ and $Y$ has type $2$ (Exercise \ref{ex:R-bound-type}), or if each $M(\xi)$ is a scalar multiplication operator (Exercise \ref{ex:scalars}), the Mikhlin norm of $M$ is equivalent to the uniform bound
\begin{equation*}
  \|M\|_{\mf{M}(\R;X,Y)} \simeq \sup_{\xi \in \bigcup_{I \in \mc{J}} I} \Big( \|M(\xi)\|_{\Lin(X,Y)} + |\xi|\|M'(\xi)\|_{\Lin(X,Y)} \Big).
\end{equation*}

\begin{thm}\label{thm:Mikhlin}\index{theorem!Mikhlin}
  Let $X$ and $Y$ be complex UMD spaces, and suppose that $M \in L^\infty(\R;\Lin(X,Y))$ is a Mikhlin symbol.
  Then for all $\mb{f} \in C_{c}^\infty(\R;X)$ and all $p \in (1,\infty)$,
  \begin{equation*}
    \|T_{M} \mb{f}\|_{L^p(\R;Y)} \lesssim_{p,X,Y} \|M\|_{\mf{M}(\R;X,Y)} \|\mb{f}\|_{L^p(\R;X)}.
  \end{equation*}
  In particular $T_{M}$ extends to a bounded operator $L^p(\R;X) \to L^p(\R;Y)$.
\end{thm}

We prove this theorem in a few steps.
We start with $R$-boundedness of the set of `localised' Fourier multipliers $T_{\1_{I} M}$, where $I$ ranges over the set of all Littlewood--Paley intervals.\footnote{This lemma implies in particular that these truncated Fourier multipliers are uniformly bounded $L^p(\R;X) \to L^p(\R;Y)$.}

\begin{lem}\label{lem:Mikhlin-components-R}\index{R-bounds@$R$-bounds!of localised Mikhlin multipliers}
  Let $X$ and $Y$ be UMD spaces, $p \in (1,\infty)$, and let $M \in \mf{M}(\R;X,Y)$ be a Mikhlin symbol.
  Then the set of truncated Fourier multipliers
  \begin{equation*}
    \{T_{\1_{I} M} : I \in \mc{J}\} \subset \Lin(L^p(\R;X), L^p(\R;Y))
  \end{equation*}
  has $R$-bound $\lesssim_{p,X,Y} \|M\|_{\mf{M}(\R;X,Y)}$.
\end{lem}

\begin{proof}
  By Example \ref{eg:R-bounded-unions} it suffices to consider $I \in \mc{J}_{+}$ and $I \in \mc{J}_{-}$ separately.
  We will only give the argument for $\mc{J}_{+}$, as only a change of notation is needed to handle $\mc{J}_{-}$.

  For each interval $I = \mc{J}_{+}$, write $I = (\ell(I), r(I))$ and let $\midp(I)$ be the midpoint of $I$.
  Then for $\xi \in I$ we have the identity
  \begin{equation*}
    \begin{aligned}
      \1_{I}(\xi)M(\xi)
      &= \1_{I}(\xi) \Big( M(\midp(I)) + \int_{\midp(I)}^{\xi} M'(\eta) \, \dd\eta \Big) \\
      &= \1_{I}(\xi) \Big( M(\midp(I)) + \int_{\ell(I)}^{\xi} M'(\eta) \, \dd\eta - \int_{\ell(I)}^{\midp(I)} M'(\eta) \, \dd\eta \Big) \\
      &= \1_{I}(\xi) \Big( M(\midp(I)) - \int_{\ell(I)}^{\midp{I}} M'(\eta) \, \dd\eta \Big) + \int_{I} \1_{(\eta,r(I))}(\xi) M'(\eta) \, \dd\eta.
    \end{aligned}
  \end{equation*}
  A change of variables leads to the Fourier multiplier identity
  \begin{equation*}
    T_{\1_I M} \mb{f}
    = \Big( M(\midp(I)) - \int_{1}^{3/2} |I| M'(t|I|) \, \dd t \Big)\Delta_{I} \mb{f} + \int_{1}^{2} |I| M'(t|I|) \Delta_{(t|I|,r(I))} \mb{f} \, \dd t.
  \end{equation*}
  Consider a sequence of functions $(\mb{f}_{I})_{I \in \mc{J}_{+}}$ and estimate the $R$-bounds corresponding to the three summands above separately.
  First we have
  \begin{equation*}
    \begin{aligned}
      \big\|M(\midp(\bullet)) \Delta_{\bullet} \mb{f}_{\bullet} \big\|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;Y))}
      &\leq R\big( \{M(\midp(I)) : I \in \mc{J}_{+} \} \big) \|\Delta_{\bullet} \mb{f}_{\bullet} \|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))} \\
      &\lesssim_{p,X} \|M\|_{\mf{M}(\R;X,Y)} \| \mb{f}_{\bullet} \|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))} 
  \end{aligned}
\end{equation*}
using the definition of the Mikhlin norm, and that the set of Fourier projections $\{\Delta_{I} : I \in \mc{J}_{+}\} \subset L^p(\R;X)$ is $R$-bounded, since $X$ is UMD and $p \in (1,\infty)$ (Proposition \ref{prop:Fproj-Rbd}).
For the second term we have
\begin{equation*}
  \begin{aligned}
    &\Big\| \Big( \int_{1}^{3/2} |\bullet|  M'(t|\bullet|) \, \dd t \Big)\Delta_{\bullet} \mb{f}_{\bullet} \Big\|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;Y))} \\
    &\qquad \leq \int_{1}^{3/2} \big\| t|\bullet|  M'(t|\bullet|)\Delta_{\bullet} \mb{f}_{\bullet} \big\|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))} \, \frac{\dd t}{t}.
  \end{aligned}
\end{equation*}
For each $t \in [1,2)$ we have
\begin{equation*}
  \begin{aligned}
    \big\| t|\bullet|  M'(t|\bullet|)\Delta_{\bullet} \mb{f}_{\bullet} \big\|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;Y))} 
    &\leq R\big( \{ t|I|  M'(t|I|) : I \in \mc{J}_{+}\} \big) \| \Delta_{\bullet} \mb{f}_{\bullet} \|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))} \\
    &\lesssim_{p,X} \|M\|_{\mf{M}(\R;X,Y)} \| \mb{f}_{\bullet} \|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))}
  \end{aligned}
\end{equation*}
again using the definition of the Mikhlin norm and Proposition \ref{prop:Fproj-Rbd}.
The third term is estimated in exactly the same way, so we omit the argument.
All up we get
\begin{equation*}
  \begin{aligned}
    \big\|T_{\1_{\bullet} M} \mb{f}_{\bullet} \big\|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;Y))}
    \lesssim \|\mb{f}_{\bullet} \|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))},
  \end{aligned}
\end{equation*}
which proves the desired $R$-bound for $\mc{J}_{+}$.
As already mentioned, the same argument adapts to $\mc{J}_{-}$, and this is sufficient to establish the claimed $R$-bound.
\end{proof}

Next we recall a reparametrised version of the Rademacher average estimate from Corollary \ref{cor:intop-bounds}.
In what follows we let
\begin{equation*}
  \phi(x) = \phi^{h}(x) = \int_{\R} h(x+u) h(u) \, \dd u
\end{equation*}
using the notation from Proposition \ref{prop:shift-average-repn}.
This function can be computed explicitly, although in this case we don't actually need the explicit representation (Exercise \ref{ex:phi-computation}): it is the piecewise affine even function supported on $[-1,1]$ which interpolates between the values
\begin{equation}\label{eq:phi-2}
  \begin{aligned}
    \phi(0) &= 1 \\ 
    \phi(1/2) &= -1/2 \\
    \phi(1) &= 0.
  \end{aligned}
\end{equation}
For each interval $I \in \mc{J}$ define
\begin{equation*}
  \phi_{I}(x) := 2|I|\phi(2|I|x) = \phi_{1/2|I|}(x)
\end{equation*}
(this is not the same as the definition of $k_{I}$ in the previous section when $k$ is an admissible base function).

\begin{lem}\label{lem:reparam-LP}
  Let $X$ be a UMD space and $p \in (1,\infty)$.
  Then for all $\mb{f} \in L^p(\R;X)$,
  \begin{equation*}
    \| \phi_{\bullet} \ast \mb{f} \|_{\varepsilon_{\mc{J}_{\pm}}(L^p(\R;X))} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}.
  \end{equation*}
\end{lem}

\begin{proof}
  Applying Corollary \ref{cor:intop-bounds} with $k = h$ yields
  \begin{equation*}
    \E \Big\| \sum_{j = m}^{n} \varepsilon_{j} \phi_{2^{-j}} \ast \mb{f} \Big\|_{L^p(\R;X)} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}.
  \end{equation*}
  For each pair of integers $m \leq n$.
  The second part of Exercise \ref{ex:on-rad-spaces} then lets us take the limit as $m \downarrow -\infty$ and $n \uparrow \infty$, and
  \begin{equation*}
    \| \phi_{2^{-\bullet}} \ast \mb{f} \|_{\varepsilon_{\Z}(L^p(\R;X))} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}.
\end{equation*}
The result follows simply by noting that the sets $\{2^{-j} : j \in \Z\}$ and $\{1/2|I| : I \in \mc{J}_{\pm}\}$ are equal.
\end{proof}

Besides one technical computation, we are ready to prove the Mikhlin multiplier theorem.
Let's just get straight to it and address the technical computation when it arises.

\begin{proof}[Proof of Theorem \ref{thm:Mikhlin}]
  By density and duality, it suffices to prove the estimate
  \begin{equation*}
    |\langle T_{M} \mb{f}, \mb{g} \rangle| \lesssim_{p,X} \|M\|_{\mf{M}(\R;X,Y)} \|\mb{f}\|_{L^p(\R;X)} \|\mb{g}\|_{L^{p'}(\R;Y^{*})}
  \end{equation*}
  for all $\mb{f} \in C_{c}^\infty(\R;X)$ and $\mb{g} \in C_{c}^\infty(\R;Y^*)$.
  Fix such functions and write, using Exercise \ref{ex:fourier-inversion} for the Fourier inversion,
  \begin{equation*}
    \langle T_{M} \mb{f}, \mb{g} \rangle
    = \langle M\hat{\mb{f}}, \check{\mb{g}} \rangle
    = \sum_{I \in \mc{J}} \langle \1_{I} M\hat{\mb{f}}, \check{\mb{g}} \rangle
    = \sum_{\sigma \in \{-,+\}} \sum_{I \in \mc{J}_{\sigma}} \langle \1_{I} M\hat{\mb{f}}, \check{\mb{g}} \rangle.
  \end{equation*}
  For simplicity we will only consider the contributions from $\mc{J}_{+}$; $\mc{J}_{-}$ is handled in exactly the same way and the estimates can be summed.
  We smuggle in the functions $\phi_{I}$:
  \begin{equation*}
    \begin{aligned}
    \sum_{I \in \mc{J}_{+}} \langle \1_{I} M\hat{\mb{f}}, \check{\mb{g}} \rangle
    &= \sum_{I \in \mc{J}_{+}} \big\langle \frac{\1_{I} M}{\widehat{\phi_{I}} \widecheck{\phi_{I}}} \widehat{\phi_{I}} \hat{\mb{f}}, \widecheck{\phi_{I}} \check{\mb{g}} \big\rangle \\
    &= \sum_{I \in \mc{J}_{+}} \big\langle \1_{I} N \widehat{\phi_{I}} \hat{\mb{f}}, \widecheck{\phi_{I}} \check{\mb{g}} \big\rangle \\
    &=\sum_{I \in \mc{J}_{+}} \big\langle T_{\1_{I} N} (\phi_{I} \ast \mb{f}) , \phi_{I} \ast \mb{g} \big\rangle
  \end{aligned}
  \end{equation*}
where
\begin{equation*}
  N := \sum_{I \in \mc{J}} \frac{\1_{I} M}{\widehat{\phi_{I}} \widecheck{\phi_{I}}}
\end{equation*}
and where Exercise \ref{ex:fourier-inversion} was used again in the last line.
In Lemma \ref{lem:N-symbol} we will show that $N$ is a Mikhlin symbol, with
\begin{equation}\label{eq:N-bound}
  \|N\|_{\mf{M}(\R;X,Y)} \lesssim \|M\|_{\mf{M}(\R;X,Y)},
\end{equation}
but for now we will assume this result and proceed.
We use the Rademacher space Cauchy--Schwartz inequality (Proposition \ref{prop:rademacher-CS}) and Kahane--Khintchine to write
\begin{equation*}
  \begin{aligned}
    &\Big| \sum_{I \in \mc{J}_{+}} \big\langle T_{\1_{I} N} (\phi_{I} \ast \mb{f}) , \phi_{I} \ast \mb{g} \big\rangle \Big| \\
    &\leq \big\| T_{\1_{\bullet} N} (\phi_{\bullet} \ast \mb{f}) \big\|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;Y))}
    \| \phi_{\bullet} \ast \mb{g} \|_{\varepsilon_{\mc{J}_{+}}(L^{p'}(\R;Y^{*}))} \\
    &\lesssim_{p,X,Y} \|N\|_{\mf{M}(\R;X,Y)} \| \phi_{\bullet} \ast \mb{f} \|_{\varepsilon_{\mc{J}_{+}}(L^p(\R;X))}
    \|\phi_{\bullet} \ast \mb{g} \|_{\varepsilon_{\mc{J}_{+}}(L^{p'}(\R;Y^{*}))} \\
  \end{aligned}
\end{equation*}
with Lemma \ref{lem:Mikhlin-components-R} being used in the last line.
We use \eqref{eq:N-bound} and Lemma \ref{lem:reparam-LP} to bound this by
\begin{equation*}
  \|M\|_{\mf{M}(\R;X,Y)} \| \mb{f} \|_{L^p(\R;X)} \| \mb{g} \|_{L^p(\R;Y^{*})},
\end{equation*}
which will complete the proof once we have proven \eqref{eq:N-bound}.
\end{proof}

It remains to control the symbol $N$ defined in the proof.

\begin{lem}\label{lem:N-symbol}
  Let $X$ and $Y$ be Banach spaces, and suppose $M \in L^\infty(\R;\Lin(X,Y))$ is a Mikhlin symbol.
  Let $\phi$ be defined as above.
  Then the function
  \begin{equation*}
    N := \sum_{I \in \mc{J}} \frac{\1_{I} M}{\widehat{\phi_{I}} \widecheck{\phi_{I}}}
  \end{equation*}
  is a Mikhlin symbol, and
  \begin{equation*}
    \|N\|_{\mf{M}(\R;X,Y)} \lesssim \|M\|_{\mf{M}(\R;X,Y)}
  \end{equation*}
\end{lem}

\begin{proof}
  Fairly straightforward estimates show that the product of Mikhlin symbols is a Mikhlin symbol, with multiplicativity of the Mikhlin norms, so we have
  \begin{equation*}
     \|N\|_{\mf{M}(\R;X,Y)} \leq \|M\|_{\mf{M}(\R;X,Y)} \Big\| \sum_{I \in \mc{J}} \frac{\1_{I} }{\widehat{\phi_{I}}} \Big\|_{\mf{M}(\R)} \Big\| \sum_{I \in \mc{J}} \frac{\1_{I} }{\widecheck{\phi_{I}}} \Big\|_{\mf{M}(\R)}.
   \end{equation*}
   Furthermore, dilation and reflection invariance shows that
   \begin{equation*}
     \Big\| \sum_{I \in \mc{J}} \frac{\1_{I} }{\widehat{\phi_{I}}} \Big\|_{\mf{M}(\R)}
     = \Big\| \sum_{I \in \mc{J}} \frac{\1_{I} }{\widecheck{\phi_{I}}} \Big\|_{\mf{M}(\R)}
     = \sup_{I \in \mc{J_{+}}} \Big\| \frac{\1_{I}}{\widehat{\phi_{I}}} \Big\|_{\mf{M}(\R)}
     = \Big\| \frac{\1_{[1/2,1)}}{\hat{\phi}} \Big\|_{\mf{M}(\R)}.
   \end{equation*}
   By definition we have
   \begin{equation*}
     \begin{aligned}
       \Big\| \frac{\1_{[1/2,1)}}{\widehat{\phi}} \Big\|_{\mf{M}(\R)}
       &= \sup_{\xi \in (1/2, 1)} \Big( \frac{1}{|\hat{\phi}(\xi)|}  + \xi\Big|\Big(\frac{1}{\hat{\phi}}\Big)'(\xi) \Big| \Big) \\
       &= \sup_{\xi \in (1/2, 1)} \Big( \frac{1}{|\hat{\phi}(\xi)|}  + \xi\Big|\frac{\hat{\phi}'(\xi)}{\hat{\phi}(\xi)^2}\Big| \Big)
   \end{aligned}
   \end{equation*}
   assuming all the quantities here make sense.
   Since $\phi$ is bounded and compactly supported, $\hat{\phi}$ is continuously differentiable, so to bound this quantity it suffices to show that
   \begin{equation}\label{eq:phi-0}
     \hat{\phi}(\xi) \neq 0 \qquad \forall \xi \in [1/2, 1].
   \end{equation}
   Since $\phi = h \ast \Refl(h)$ we have
   \begin{equation*}
     \hat{\phi}(\xi) = \hat{h}(\xi) \hat{h}(-\xi).
   \end{equation*}
   A direct computation gives
   \begin{equation*}
     \begin{aligned}
     \hat{h}(\xi) = \widehat{\1_{[0,1/2)}}(\xi) - \widehat{\1_{[1/2,1)}}(\xi)
     &= \int_{0}^{1/2} e^{-2\pi i x \xi} \, \dd x - \int_{1/2}^{1} e^{-2\pi i x \xi} \, \dd x \\
     &= - \Big[ \frac{e^{-2\pi i x\xi}}{2\pi i \xi} \Big]_{x=0}^{1/2} + \Big[ \frac{-e^{-2\pi i x\xi}}{2\pi i \xi} \Big]_{x=1/2}^{1} \\
     &= \frac{-1}{2\pi i \xi} \Big( e^{-\pi i \xi} - 1 - e^{-2\pi i \xi} + e^{-\pi i \xi}\Big) \\
     &= \frac{1}{2\pi i \xi} \Big( e^{-2\pi i \xi} - 2e^{-\pi i \xi} + 1 \Big).
   \end{aligned}
 \end{equation*}
 This vanishes if and only if $e^{-\pi i \xi} = 1$,\footnote{This can be seen geometrically, or just by solving the quadratic equation in $e^{-\pi i \xi}$.} which happens if and only if $\xi \in 2\Z$.
 This establishes \eqref{eq:phi-0} and completes the proof.
\end{proof}

We conclude this section with the Littlewood--Paley theorem for UMD-valued functions on the real line.\footnote{In a sense, Lemma \ref{lem:reparam-LP} is already a Littlewood--Paley theorem with a piecewise affine cutoff. As in the scalar-valued case, in one dimension (i.e. on $\R$) no regularity is needed on the cutoff function: characteristic functions on Littlewood--Paley intervals suffice. In higher dimensions (i.e. on $\R^{d}$) smoother cutoffs are needed, as in the scalar-valued case. See \cite[Theorem 5.5.22]{HNVW16},}

\begin{thm}[Littlewood--Paley]\label{thm:LittlewoodPaley}\index{theorem!Littlewood--Paley}
  Let $X$ be a complex UMD space and $p \in (1,\infty)$.
  Then for all $\mb{f} \in L^p(\R;X)$,
  \begin{equation*}
    \|\mb{f}\|_{L^p(\R;X)} \simeq_{p,X} \big\| \Delta_{\bullet} \mb{f} \big\|_{\varepsilon_{\mc{J}}(L^p(\R;X))}.
  \end{equation*}
\end{thm}

\begin{proof}
  Consider the Fourier multiplier with scalar-valued symbol
  \begin{equation*}
    m := \sum_{I \in \mc{J}} a_{I} \1_{I},
  \end{equation*}
  where $a_{I} \in \{-1,+1\}$ for all $I \in \mc{J}$.
  Then $m$ is almost trivially a Mikhlin symbol, and we have
  \begin{equation*}
    \Big\| \sum_{I \in \mc{J}} a_{I} \Delta_{I} \mb{f} \Big\|_{L^p(\R;X)} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}.
  \end{equation*}
  Applying this to the function $\mb{g} = \sum_{I \in \mc{J}} a_{I} \Delta_{I} \mb{f}$ proves the reverse estimate
  \begin{equation*}
    \|\mb{f}\|_{L^p(\R;X)} \lesssim_{p,X} \Big\| \sum_{I \in \mc{J}} a_{I} \Delta_{I} \mb{f} \Big\|_{L^p(\R;X)}.
  \end{equation*}
  Averaging both of these estimates over all choices of signs (i.e. replacing $a_{\bullet}$ with a Rademacher sequence) completes the proof.
\end{proof}

An alternative proof of the estimate
\begin{equation*}
  \big\| \Delta_{\bullet} \mb{f} \big\|_{\varepsilon_{\mc{J}}(L^p(\R;X))} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}
\end{equation*}
is sketched in Exercise \ref{ex:LP-op-2}.
This proof is more difficult, but directly interprets this estimate as the boundedness of a single operator-valued Fourier multiplier, while the proof above uses boundedness of infinitely many scalar-valued Fourier multipliers.

\section*{Exercises}

\begin{exercise}\label{ex:dyadic-dichotomy}\index{dyadic dichotomy}
  Prove the dyadic dichotomy for shifted dyadic systems: if $\omega \in \{0,1\}^{\Z}$ and $I,J \in \mc{D}^{\omega}$, then either $I$ and $J$ are comparable (i.e. $I \subseteq J$ or $J \subseteq I$) or disjoint ($I \cap J = \varnothing$).
\end{exercise}

\begin{exercise}\label{ex:dyadic-refln-invariance}
  Show that the set of shifted dyadic systems is reflection invariant, i.e. that $-\mc{D}^{\omega} = \mc{D}^{\omega'}$ for some $\omega' \in \{0,1\}^{\Z}$.
\end{exercise}

\begin{exercise}\label{ex:mgale-reduction}
  Complete the proof of Theorem \ref{thm:general-haar-decompositions}.
\end{exercise}

\begin{exercise}
  Let $k$ be an admissible base function, $\mc{D} = t\mc{D}^{\omega}$ a generalised dyadic system, and $X$ any Banach space.
  Show that for all $m \leq n$, the truncated dyadic shift $S_{k,m,n}^{t,\omega}$ is bounded on $L^\infty(\R;X)$.
\end{exercise}

\begin{exercise}
  Let $X$ be a complex Banach space and $\mb{f} \in L^1(\R;X)$.
  Suppose that $\hat{\mb{f}} \in L^1(\R;X)$.
  Show that there exists a continuous function $\mb{g} \colon \R \to X$ such that $\mb{f} \aeeq \mb{g}$.
\end{exercise}

\begin{exercise}\label{ex:R-bound-type}\index{R-bounds@$R$-bounds!equivalence with uniform bounds}
  Let $X$ be a Banach space with cotype $2$ and $Y$ a Banach space with type $2$.
  Show that $R$-boundedness of a set of operators $\mc{T} \subset \Lin(X,Y)$ is equivalent to uniform boundedness.\footnote{The converse is also true: if uniform boundedness implies $R$-boundedness for every $\mc{T} \subset \Lin(X,Y)$, then $X$ has cotype $2$ and $Y$ has type $2$. See \cite[Proposition 8.6.1]{HNVW17}.\ }
\end{exercise}

\begin{exercise}\label{ex:scalars}\index{R-bounds@$R$-bounds!of sets of scalars}
  Let $X$ be a Banach space, and for each scalar $\lambda \in \K$ consider the operator $m_{\lambda}(\mb{x}) := \lambda \mb{x}$.
  For each $C < \infty$, show that the set
  \begin{equation*}
    \{m_{\lambda} : |\lambda| \leq C\} \subset \Lin(X)
  \end{equation*}
  is $R$-bounded.
\end{exercise}

\begin{exercise}\label{ex:R-bound-stuff}
  Let $X$, $Y$, and $Z$ be Banach spaces, and let $\mc{T} \subset \Lin(X,Y)$ and $\mc{T}' \subset \Lin(Y,Z)$ be $R$-bounded sets of operators.
  Show the $R$-bounds
  \begin{equation*}
    R\big(\{A - A' : A,A' \in \mc{T}\} \big) \leq 2R(\mc{T})
  \end{equation*}
  and
  \begin{equation*}
    R\big(\{AB : A \in \mc{T}', B \in \mc{T}\}\big) \leq R(\mc{T})R(\mc{T}').
  \end{equation*}
\end{exercise}

\begin{exercise}\label{ex:fourier-inversion}
  Let $X$ be a complex Banach space.
  For functions $\mb{f} \in L^1(\R;X)$ and $\mb{g} \in L^1(\R;X^{*})$ with integrable Fourier transforms, prove that
  \begin{equation*}
    \int_{\R} \langle \hat{\mb{f}}(\xi), \check{\mb{g}}(\xi) \rangle \, \dd\xi
    = \int_{\R} \langle \mb{f}(x), \mb{g}(x) \rangle \, \dd x.
  \end{equation*}
\end{exercise}

\begin{exercise}\label{ex:LP-op-2}\index{theorem!Littlewood--Paley}
  Let $X$ be a complex UMD space and $p \in (1,\infty)$.
  Prove the one-sided Littlewood--Paley estimate
  \begin{equation*}
    \E \Big\| \sum_{I \in \mc{J}} \varepsilon_{I} \Delta_{I} \mb{f} \Big\|_{L^p(\R;X)} \lesssim_{p,X} \|\mb{f}\|_{L^p(\R;X)}
  \end{equation*}
  via the Mikhlin theorem by considering the operator-valued symbol
  \begin{equation*}
    M \in L^\infty(\R; \Lin(X, \varepsilon_{\mc{J}}(X)))
  \end{equation*}
  defined by
  \begin{equation*}
    (M(\xi)\mb{x})_{I} := \1_{I}(\xi)\mb{x} \qquad \forall I \in \mc{J}.
  \end{equation*}
\end{exercise}

\begin{exercise}\label{ex:phi-computation}
  Explicitly compute the functions $\phi^{k}$ and $\phi^{h}$ appearing in \eqref{eq:phi-1} and \eqref{eq:phi-2}.\footnote{Hint: compute their derivatives instead. Think like a lazy physicist.}
\end{exercise}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main.tex"
%%% End:
